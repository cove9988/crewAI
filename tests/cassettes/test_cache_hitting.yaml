interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role.\ntest backstory\n\nYour
      personal goal is: test goalTOOLS:\n------\nYou have access to only the following
      tools:\n\n(''multiplier: multiplier(first_number: int, second_number: int) ->
      float - Useful for when you need to multiply two numbers together.'',)\n\nTo
      use a tool, please use the exact following format:\n\n```\nThought: Do I need
      to use a tool? Yes\nAction: the tool you wanna use, should be one of [multiplier],
      just the name.\nAction Input: Any and all relevant information input and context
      for using the tool\nObservation: the result of using the tool\n```\n\nWhen you
      have a response for your task, or if you do not need to use a tool, you MUST
      use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer:
      [your response here]```This is the summary of your work so far:\nBegin! This
      is VERY important to you, your job depends on it!\n\nCurrent Task: What is 2
      times 6?\n"}], "model": "gpt-4", "n": 1, "stop": ["\nObservation"], "stream":
      true, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1051'
      content-type:
      - application/json
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Thought"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Yes"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        multiplier"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Input"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        {''"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"first"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_number"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"'':"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"2"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        ''"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"second"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_number"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"'':"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"6"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"}"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5DX94fS0HstZcXKAxguNWcswNt","object":"chat.completion.chunk","created":1707815375,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854beeed8b3e67e9-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 09:09:36 GMT
      Server:
      - cloudflare
      Set-Cookie:
      - __cf_bm=wYRA1FuQcmwu05Sih00GjdQGNRobansjUL23cxbLWWw-1707815376-1-AaUp94LEMTGo41Vt8g1j2P/si0MaByYCRMNbqb/UTa3EjY6kB9ukBhxNFKPj9WUPRHvnYaGzlAHm/ofJAcVpA8c=;
        path=/; expires=Tue, 13-Feb-24 09:39:36 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=VgXK5cATyw1hqOD8UJ0mKVAnMkdOukzfksEq67GApQA-1707815376364-0-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '526'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299760'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 48ms
      x-request-id:
      - req_a5cd130b34447cc0b406320963de4910
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "\n                                The
      schema should have the following structure, only two key:\n                                -
      tool_name: str\n                                - arguments: dict (with all
      arguments being passed)\n\n                                Example:\n                                {\"tool_name\":
      \"tool_name\", \"arguments\": {\"arg_name1\": \"value\", \"arg_name2\": 2}}\n                            "},
      {"role": "user", "content": "Tools available:\n\nTool Name: multiplier\nTool
      Description: multiplier(first_number: int, second_number: int) -> float - Useful
      for when you need to multiply two numbers together.\nTool Arguments: {''first_number'':
      {''type'': ''integer''}, ''second_number'': {''type'': ''integer''}}\n\nReturn
      a valid schema for the tool, use this text to inform a valid ouput schema:\n\nTool
      Name: multiplier\nTool Arguments: {''first_number'': 2, ''second_number'': 6}```"}],
      "model": "gpt-4", "function_call": {"name": "InstructorToolCalling"}, "functions":
      [{"name": "InstructorToolCalling", "description": "Correctly extracted `InstructorToolCalling`
      with all the required parameters with correct types", "parameters": {"properties":
      {"tool_name": {"description": "The name of the tool to be called.", "title":
      "Tool Name", "type": "string"}, "arguments": {"description": "A dictinary of
      arguments to be passed to the tool.", "title": "Arguments", "type": "object"}},
      "required": ["arguments", "tool_name"], "type": "object"}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1510'
      content-type:
      - application/json
      cookie:
      - __cf_bm=wYRA1FuQcmwu05Sih00GjdQGNRobansjUL23cxbLWWw-1707815376-1-AaUp94LEMTGo41Vt8g1j2P/si0MaByYCRMNbqb/UTa3EjY6kB9ukBhxNFKPj9WUPRHvnYaGzlAHm/ofJAcVpA8c=;
        _cfuvid=VgXK5cATyw1hqOD8UJ0mKVAnMkdOukzfksEq67GApQA-1707815376364-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1ySTWvcMBCG7/4VYs7esh/ebOJbCC1JaW+hUOpgtLLWq1SaEdIYki7+70Vrr9fJ
        xRg98z68HvmUCQGmgVKAOkpWztvFbXjdPvp/P4v7X0X3bX3/XX19XDbG/Xj6/byBPCVo/6oVX1Jf
        FDlvNRvCAaugJetkXe2Wu9vVdrO7OwNHjbYp1npeFIvlzWoUqiMZpSOU4k8mhBCn8zN1w0a/QSmW
        +eXE6Rhlq6GchoSAQDadgIzRRJbIkF+hImSNqS521s7AoUOVWtdKWvtBKASgdGflE0YOnWIKz0T2
        QVprsJ3phQAZ2s5p5NQfThWmwwqYyNbJUkEpKnCdZeOt0aGC/DIzJdPMmBzIwYTINXZunwKlWOdz
        GrUibGb4ZqB9hT1M1frxrZ+WZ6n1gfbx0y7gYNDEYx20jITpKyKTH0RJ8nK+pO7D3sEHcp5rpr8a
        k3BdbAcfXP+HK90UI2RiaWep3V02NoT4Hlm7+mCw1cEHM91Z1mf/AQAA//8DAJMpuJiqAgAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854bef0a680067e9-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 13 Feb 2024 09:09:42 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '2964'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299770'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 45ms
      x-request-id:
      - req_66fe538e3699ea9901ef4af0230425cc
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role.\ntest backstory\n\nYour
      personal goal is: test goalTOOLS:\n------\nYou have access to only the following
      tools:\n\n(''multiplier: multiplier(first_number: int, second_number: int) ->
      float - Useful for when you need to multiply two numbers together.'',)\n\nTo
      use a tool, please use the exact following format:\n\n```\nThought: Do I need
      to use a tool? Yes\nAction: the tool you wanna use, should be one of [multiplier],
      just the name.\nAction Input: Any and all relevant information input and context
      for using the tool\nObservation: the result of using the tool\n```\n\nWhen you
      have a response for your task, or if you do not need to use a tool, you MUST
      use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer:
      [your response here]```This is the summary of your work so far:\nBegin! This
      is VERY important to you, your job depends on it!\n\nCurrent Task: What is 2
      times 6?\nThought: Do I need to use a tool? Yes\nAction: multiplier\nAction
      Input: {''first_number'': 2, ''second_number'': 6}\nObservation: 12\nThought:
      "}], "model": "gpt-4", "n": 1, "stop": ["\nObservation"], "stream": true, "temperature":
      0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1191'
      content-type:
      - application/json
      cookie:
      - __cf_bm=wYRA1FuQcmwu05Sih00GjdQGNRobansjUL23cxbLWWw-1707815376-1-AaUp94LEMTGo41Vt8g1j2P/si0MaByYCRMNbqb/UTa3EjY6kB9ukBhxNFKPj9WUPRHvnYaGzlAHm/ofJAcVpA8c=;
        _cfuvid=VgXK5cATyw1hqOD8UJ0mKVAnMkdOukzfksEq67GApQA-1707815376364-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        No"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"2"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        times"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"6"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        is"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"12"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"."},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5KQIBbjWoVlg8EFZEdeOO2hgzy","object":"chat.completion.chunk","created":1707815382,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854bef1dedaa67e9-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 09:09:43 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '378'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299725'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 54ms
      x-request-id:
      - req_159628d2cdf1c45bd3fff274e852023f
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Progressively summarize the
      lines of conversation provided, adding onto the previous summary returning a
      new summary.\n\nEXAMPLE\nCurrent summary:\nThe human asks what the AI thinks
      of artificial intelligence. The AI thinks artificial intelligence is a force
      for good.\n\nNew lines of conversation:\nHuman: Why do you think artificial
      intelligence is a force for good?\nAI: Because artificial intelligence will
      help humans reach their full potential.\n\nNew summary:\nThe human asks what
      the AI thinks of artificial intelligence. The AI thinks artificial intelligence
      is a force for good because it will help humans reach their full potential.\nEND
      OF EXAMPLE\n\nCurrent summary:\n\n\nNew lines of conversation:\nHuman: What
      is 2 times 6?\nAI: 2 times 6 is 12.\n\nNew summary:"}], "model": "gpt-4", "n":
      1, "stream": false, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '886'
      content-type:
      - application/json
      cookie:
      - __cf_bm=wYRA1FuQcmwu05Sih00GjdQGNRobansjUL23cxbLWWw-1707815376-1-AaUp94LEMTGo41Vt8g1j2P/si0MaByYCRMNbqb/UTa3EjY6kB9ukBhxNFKPj9WUPRHvnYaGzlAHm/ofJAcVpA8c=;
        _cfuvid=VgXK5cATyw1hqOD8UJ0mKVAnMkdOukzfksEq67GApQA-1707815376364-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1SRy27CMBBF9/mKkddQJYFAml1VseiiXbGoVFXIOENi8EueiVSE+PfK4dVubOne
        OeM741MGIHQrGhCql6xsMNM67quP9/xTRfWK+XZZ5uWxXte8X62oEpNE+O0eFd+oJ+VtMMjau4ut
        IkrG1LVY5su6qGZ1NRrWt2gS1gWezqf5ophdid5rhSQa+MoAAE7jmbK5Fn9EA/nkplgkkh2K5l4E
        IKI3SRGSSBNLx2LyMJV3jG6Mu+4R+sFKB5IOBNwjvLyNV0QaDIPfgR0M62CO2nVQwvYIiwlI196K
        I1Lwrk2wZCiBtUWCBWiConwS12fP97zGdyH6bZrNDcbc9Z12mvpNREnepWzEPlzwcwbwPe5l+Deq
        CNHbwBv2B3SpYVFVl37i8QUPt3y+muxZmj9UPc+uCQUdidFudtp1GEPU45pSzuyc/QIAAP//AwCg
        I2s9HQIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854bef2f5b1467e9-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 13 Feb 2024 09:09:48 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '2817'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299794'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 41ms
      x-request-id:
      - req_c0f095d6f7d6b78e5c16dbd6d79ad39a
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role.\ntest backstory\n\nYour
      personal goal is: test goalTOOLS:\n------\nYou have access to only the following
      tools:\n\n(''multiplier: multiplier(first_number: int, second_number: int) ->
      float - Useful for when you need to multiply two numbers together.'',)\n\nTo
      use a tool, please use the exact following format:\n\n```\nThought: Do I need
      to use a tool? Yes\nAction: the tool you wanna use, should be one of [multiplier],
      just the name.\nAction Input: Any and all relevant information input and context
      for using the tool\nObservation: the result of using the tool\n```\n\nWhen you
      have a response for your task, or if you do not need to use a tool, you MUST
      use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer:
      [your response here]```This is the summary of your work so far:\nThe human asks
      the AI the result of multiplying 2 by 6, and the AI responds that 2 times 6
      is 12.Begin! This is VERY important to you, your job depends on it!\n\nCurrent
      Task: What is 3 times 3?\n"}], "model": "gpt-4", "n": 1, "stop": ["\nObservation"],
      "stream": true, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1148'
      content-type:
      - application/json
      cookie:
      - __cf_bm=wYRA1FuQcmwu05Sih00GjdQGNRobansjUL23cxbLWWw-1707815376-1-AaUp94LEMTGo41Vt8g1j2P/si0MaByYCRMNbqb/UTa3EjY6kB9ukBhxNFKPj9WUPRHvnYaGzlAHm/ofJAcVpA8c=;
        _cfuvid=VgXK5cATyw1hqOD8UJ0mKVAnMkdOukzfksEq67GApQA-1707815376364-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Thought"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Yes"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        multiplier"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Input"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        {''"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"first"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_number"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"'':"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"3"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        ''"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"second"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_number"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"'':"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"3"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"}"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5Qd24XVC8vwrjskDPvvyD6gH8I","object":"chat.completion.chunk","created":1707815388,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854bef42098067e9-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 09:09:49 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '902'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299735'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 52ms
      x-request-id:
      - req_2b71f16b0595c4b2a2844c9cfbbc19d2
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "\n                                The
      schema should have the following structure, only two key:\n                                -
      tool_name: str\n                                - arguments: dict (with all
      arguments being passed)\n\n                                Example:\n                                {\"tool_name\":
      \"tool_name\", \"arguments\": {\"arg_name1\": \"value\", \"arg_name2\": 2}}\n                            "},
      {"role": "user", "content": "Tools available:\n\nTool Name: multiplier\nTool
      Description: multiplier(first_number: int, second_number: int) -> float - Useful
      for when you need to multiply two numbers together.\nTool Arguments: {''first_number'':
      {''type'': ''integer''}, ''second_number'': {''type'': ''integer''}}\n\nReturn
      a valid schema for the tool, use this text to inform a valid ouput schema:\n\nTool
      Name: multiplier\nTool Arguments: {''first_number'': 3, ''second_number'': 3}```"}],
      "model": "gpt-4", "function_call": {"name": "InstructorToolCalling"}, "functions":
      [{"name": "InstructorToolCalling", "description": "Correctly extracted `InstructorToolCalling`
      with all the required parameters with correct types", "parameters": {"properties":
      {"tool_name": {"description": "The name of the tool to be called.", "title":
      "Tool Name", "type": "string"}, "arguments": {"description": "A dictinary of
      arguments to be passed to the tool.", "title": "Arguments", "type": "object"}},
      "required": ["arguments", "tool_name"], "type": "object"}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1510'
      content-type:
      - application/json
      cookie:
      - __cf_bm=wYRA1FuQcmwu05Sih00GjdQGNRobansjUL23cxbLWWw-1707815376-1-AaUp94LEMTGo41Vt8g1j2P/si0MaByYCRMNbqb/UTa3EjY6kB9ukBhxNFKPj9WUPRHvnYaGzlAHm/ofJAcVpA8c=;
        _cfuvid=VgXK5cATyw1hqOD8UJ0mKVAnMkdOukzfksEq67GApQA-1707815376364-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1ySTYvbMBCG7/4Vw5ydkmySza6P3S600KWH7QelLkZRFEdbaUZIY2g2+L8XOYmT
        7cWYeeZ9eC35UACg3WAFqHdKtA9uchdflt++3/qn3ev7xz0/T3+87j8+PP/8/PT45QOWOcHrF6Pl
        nHqn2QdnxDIdsY5GicnW2Wq6upst5/c3A/C8MS7H2iCTxWR6O5ufEju22iSs4FcBAHAYnrkbbcxf
        rGBanifepKRag9W4BICRXZ6gSskmUSRYXqBmEkO5LnXOXYFtRzq3brRy7o0QAEn5QfmJksROC8ev
        zO5BOWepvdIDoIpt5w1J7o+HmgBqFGbXZEeNFdToOyc2OGtijeVxY0zljSGVp1sbkzTU+XVerWBe
        nkkymmlzjTLpa+pxLNOf3vrxuBy3IfI6/ff1uLVk066JRiWm3DsJh6MoS34P19K9OWkMkX2QRviP
        oSy8WSyPPrz8ARc6X5ygsCh3lVrdF6eGmPZJjG+2lloTQ7TjLRV98Q8AAP//AwDL8aRynAIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854bef595b4567e9-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 13 Feb 2024 09:09:55 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '2623'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299770'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 45ms
      x-request-id:
      - req_ed8287527d74158a24eab3b92f8797f4
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role.\ntest backstory\n\nYour
      personal goal is: test goalTOOLS:\n------\nYou have access to only the following
      tools:\n\n(''multiplier: multiplier(first_number: int, second_number: int) ->
      float - Useful for when you need to multiply two numbers together.'',)\n\nTo
      use a tool, please use the exact following format:\n\n```\nThought: Do I need
      to use a tool? Yes\nAction: the tool you wanna use, should be one of [multiplier],
      just the name.\nAction Input: Any and all relevant information input and context
      for using the tool\nObservation: the result of using the tool\n```\n\nWhen you
      have a response for your task, or if you do not need to use a tool, you MUST
      use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer:
      [your response here]```This is the summary of your work so far:\nThe human asks
      the AI the result of multiplying 2 by 6, and the AI responds that 2 times 6
      is 12.Begin! This is VERY important to you, your job depends on it!\n\nCurrent
      Task: What is 3 times 3?\nThought: Do I need to use a tool? Yes\nAction: multiplier\nAction
      Input: {''first_number'': 3, ''second_number'': 3}\nObservation: 9\nThought:
      "}], "model": "gpt-4", "n": 1, "stop": ["\nObservation"], "stream": true, "temperature":
      0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1287'
      content-type:
      - application/json
      cookie:
      - __cf_bm=wYRA1FuQcmwu05Sih00GjdQGNRobansjUL23cxbLWWw-1707815376-1-AaUp94LEMTGo41Vt8g1j2P/si0MaByYCRMNbqb/UTa3EjY6kB9ukBhxNFKPj9WUPRHvnYaGzlAHm/ofJAcVpA8c=;
        _cfuvid=VgXK5cATyw1hqOD8UJ0mKVAnMkdOukzfksEq67GApQA-1707815376364-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        No"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"3"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        times"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"3"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        is"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"9"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"."},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5XV7VhWmd5ZxN5vcDT1rFP55oD","object":"chat.completion.chunk","created":1707815395,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854bef6c9a3267e9-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 09:09:56 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '472'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299701'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 59ms
      x-request-id:
      - req_51cf12b3875cdd8e265ca986ef1117e8
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Progressively summarize the
      lines of conversation provided, adding onto the previous summary returning a
      new summary.\n\nEXAMPLE\nCurrent summary:\nThe human asks what the AI thinks
      of artificial intelligence. The AI thinks artificial intelligence is a force
      for good.\n\nNew lines of conversation:\nHuman: Why do you think artificial
      intelligence is a force for good?\nAI: Because artificial intelligence will
      help humans reach their full potential.\n\nNew summary:\nThe human asks what
      the AI thinks of artificial intelligence. The AI thinks artificial intelligence
      is a force for good because it will help humans reach their full potential.\nEND
      OF EXAMPLE\n\nCurrent summary:\nThe human asks the AI the result of multiplying
      2 by 6, and the AI responds that 2 times 6 is 12.\n\nNew lines of conversation:\nHuman:
      What is 3 times 3?\nAI: 3 times 3 is 9.\n\nNew summary:"}], "model": "gpt-4",
      "n": 1, "stream": false, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '982'
      content-type:
      - application/json
      cookie:
      - __cf_bm=wYRA1FuQcmwu05Sih00GjdQGNRobansjUL23cxbLWWw-1707815376-1-AaUp94LEMTGo41Vt8g1j2P/si0MaByYCRMNbqb/UTa3EjY6kB9ukBhxNFKPj9WUPRHvnYaGzlAHm/ofJAcVpA8c=;
        _cfuvid=VgXK5cATyw1hqOD8UJ0mKVAnMkdOukzfksEq67GApQA-1707815376364-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA3xRO0/DMBDe8ytOntsqaehz6wACFhjKAkKVm1wTF7/kuwgC6n9HTtNGLCy29D3O
        333+SQCEKsUaRFFLLozX42U4zl4f79PiLt3Uz5tt2ry0fvv0Wn636a0YRYfbH7Hgi2tSOOM1snL2
        TBcBJWOcmi3SxTKb5atFRxhXoo62yvP4ZpzOs7x31E4VSGINbwkAwE93xmy2xC+xhnR0QQwSyQrF
        +ioCEMHpiAhJpIilZTEayMJZRtvF3dYIdWOkBUkfBFwjbB66KyA1msEdwDSaldetshVMYd/CfATS
        lhdxQPLOltEsGabAyiDBHBRBNp3A8ALX2D/zGZWKIO/F+T8Dr5poWE1Ev8bpur92lQ9uH7uyjdZX
        /KCsonoXUJKzcVdi58/2UwLw3vXc/KlO+OCM5x27D7RxYLa8Oc8Tw5cO7GzWk+xY6gGf5qukTyio
        JUazOyhbYfBBdbXHnMkp+QUAAP//AwCT+Z0jbQIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854bef7b8d8967e9-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 13 Feb 2024 09:10:02 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '4963'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299770'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 46ms
      x-request-id:
      - req_92bbb8bee919108b056ef2248e23a4e0
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role.\ntest backstory\n\nYour
      personal goal is: test goalTOOLS:\n------\nYou have access to only the following
      tools:\n\n(''multiplier: multiplier(first_number: int, second_number: int) ->
      float - Useful for when you need to multiply two numbers together.'',)\n\nTo
      use a tool, please use the exact following format:\n\n```\nThought: Do I need
      to use a tool? Yes\nAction: the tool you wanna use, should be one of [multiplier],
      just the name.\nAction Input: Any and all relevant information input and context
      for using the tool\nObservation: the result of using the tool\n```\n\nWhen you
      have a response for your task, or if you do not need to use a tool, you MUST
      use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer:
      [your response here]```This is the summary of your work so far:\nThe human asks
      the AI the result of multiplying 2 by 6, and the AI responds that 2 times 6
      is 12. The human then asks what is 3 times 3, and the AI responds that 3 times
      3 is 9.Begin! This is VERY important to you, your job depends on it!\n\nCurrent
      Task: What is 2 times 6 times 3? Return only the number\n"}], "model": "gpt-4",
      "n": 1, "stop": ["\nObservation"], "stream": true, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1259'
      content-type:
      - application/json
      cookie:
      - __cf_bm=wYRA1FuQcmwu05Sih00GjdQGNRobansjUL23cxbLWWw-1707815376-1-AaUp94LEMTGo41Vt8g1j2P/si0MaByYCRMNbqb/UTa3EjY6kB9ukBhxNFKPj9WUPRHvnYaGzlAHm/ofJAcVpA8c=;
        _cfuvid=VgXK5cATyw1hqOD8UJ0mKVAnMkdOukzfksEq67GApQA-1707815376364-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Thought"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Yes"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        multiplier"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Input"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        {\""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"first"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_number"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"2"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        \""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"second"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_number"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"6"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"}"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5fAHwme7EPpaKaCO2Ck8kfqjqQ","object":"chat.completion.chunk","created":1707815403,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854bef9d9b4867e9-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 09:10:03 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '306'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299708'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 58ms
      x-request-id:
      - req_1492104bf09f3e442bc6ac20bbf8e4d8
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "\n                                The
      schema should have the following structure, only two key:\n                                -
      tool_name: str\n                                - arguments: dict (with all
      arguments being passed)\n\n                                Example:\n                                {\"tool_name\":
      \"tool_name\", \"arguments\": {\"arg_name1\": \"value\", \"arg_name2\": 2}}\n                            "},
      {"role": "user", "content": "Tools available:\n\nTool Name: multiplier\nTool
      Description: multiplier(first_number: int, second_number: int) -> float - Useful
      for when you need to multiply two numbers together.\nTool Arguments: {''first_number'':
      {''type'': ''integer''}, ''second_number'': {''type'': ''integer''}}\n\nReturn
      a valid schema for the tool, use this text to inform a valid ouput schema:\n\nTool
      Name: multiplier\nTool Arguments: {\"first_number\": 2, \"second_number\": 6}```"}],
      "model": "gpt-4", "function_call": {"name": "InstructorToolCalling"}, "functions":
      [{"name": "InstructorToolCalling", "description": "Correctly extracted `InstructorToolCalling`
      with all the required parameters with correct types", "parameters": {"properties":
      {"tool_name": {"description": "The name of the tool to be called.", "title":
      "Tool Name", "type": "string"}, "arguments": {"description": "A dictinary of
      arguments to be passed to the tool.", "title": "Arguments", "type": "object"}},
      "required": ["arguments", "tool_name"], "type": "object"}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1514'
      content-type:
      - application/json
      cookie:
      - __cf_bm=wYRA1FuQcmwu05Sih00GjdQGNRobansjUL23cxbLWWw-1707815376-1-AaUp94LEMTGo41Vt8g1j2P/si0MaByYCRMNbqb/UTa3EjY6kB9ukBhxNFKPj9WUPRHvnYaGzlAHm/ofJAcVpA8c=;
        _cfuvid=VgXK5cATyw1hqOD8UJ0mKVAnMkdOukzfksEq67GApQA-1707815376364-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1yRQW/bMAyF7/4VBM/OkDRJk/raoUAwYNuhl20eDEVRbLUSKUg0ui7wfx+UpK67
        iyDw8X16Ik8FANoDVoC6U6J9cLNtfFp333d/H16/qJ/yuLtfdi/fPi/V9mXz4yuW2cH7J6PlzfVJ
        sw/OiGW6yDoaJSZTF5v5ZrtYr+brs+D5YFy2tUFmq9n8drG8Ojq22iSs4FcBAHA6nzkbHcwfrGBe
        vlW8SUm1BquxCQAju1xBlZJNokiwfBc1kxjKcal3biIce9I5daOVcx+AAEjKn5E7ShJ7LRwfmd29
        cs5SO8EDoIpt7w1Jzo+nmgBqFGbXZEaNFdToeyc2OGtijeWlY3TljlONRxuTNNT7fW6q4KaEGpPR
        TIdJ9XaoacDx9eF6G8b5OG5D5H3677t4tGRT10SjElMOmoTDBZQhv8976D+MFkNkH6QRfjaUgTer
        9YWH7yufqHdXUViUm9Q3q+KaENNrEuObo6XWxBDtuJZiKP4BAAD//wMArbedx40CAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854befae984467e9-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 13 Feb 2024 09:10:08 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '2512'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299770'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 45ms
      x-request-id:
      - req_cb189b954c11e640ee08fc416dce278e
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role.\ntest backstory\n\nYour
      personal goal is: test goalTOOLS:\n------\nYou have access to only the following
      tools:\n\n(''multiplier: multiplier(first_number: int, second_number: int) ->
      float - Useful for when you need to multiply two numbers together.'',)\n\nTo
      use a tool, please use the exact following format:\n\n```\nThought: Do I need
      to use a tool? Yes\nAction: the tool you wanna use, should be one of [multiplier],
      just the name.\nAction Input: Any and all relevant information input and context
      for using the tool\nObservation: the result of using the tool\n```\n\nWhen you
      have a response for your task, or if you do not need to use a tool, you MUST
      use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer:
      [your response here]```This is the summary of your work so far:\nThe human asks
      the AI the result of multiplying 2 by 6, and the AI responds that 2 times 6
      is 12. The human then asks what is 3 times 3, and the AI responds that 3 times
      3 is 9.Begin! This is VERY important to you, your job depends on it!\n\nCurrent
      Task: What is 2 times 6 times 3? Return only the number\nThought: Do I need
      to use a tool? Yes\nAction: multiplier\nAction Input: {\"first_number\": 2,
      \"second_number\": 6}\nObservation: 12\nThought: "}], "model": "gpt-4", "n":
      1, "stop": ["\nObservation"], "stream": true, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1403'
      content-type:
      - application/json
      cookie:
      - __cf_bm=wYRA1FuQcmwu05Sih00GjdQGNRobansjUL23cxbLWWw-1707815376-1-AaUp94LEMTGo41Vt8g1j2P/si0MaByYCRMNbqb/UTa3EjY6kB9ukBhxNFKPj9WUPRHvnYaGzlAHm/ofJAcVpA8c=;
        _cfuvid=VgXK5cATyw1hqOD8UJ0mKVAnMkdOukzfksEq67GApQA-1707815376364-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Yes"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        multiplier"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Input"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        {\""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"first"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_number"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"12"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        \""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"second"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_number"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"3"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"}"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5kxEEJSVFMFRDF495ObkLskmQz","object":"chat.completion.chunk","created":1707815408,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854befbfdd1267e9-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 09:10:09 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '266'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299674'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 65ms
      x-request-id:
      - req_61c0c5c54199049f3a4938d08fb16b12
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "\n                                The
      schema should have the following structure, only two key:\n                                -
      tool_name: str\n                                - arguments: dict (with all
      arguments being passed)\n\n                                Example:\n                                {\"tool_name\":
      \"tool_name\", \"arguments\": {\"arg_name1\": \"value\", \"arg_name2\": 2}}\n                            "},
      {"role": "user", "content": "Tools available:\n\nTool Name: multiplier\nTool
      Description: multiplier(first_number: int, second_number: int) -> float - Useful
      for when you need to multiply two numbers together.\nTool Arguments: {''first_number'':
      {''type'': ''integer''}, ''second_number'': {''type'': ''integer''}}\n\nReturn
      a valid schema for the tool, use this text to inform a valid ouput schema:\nDo
      I need to use a tool? Yes\nTool Name: multiplier\nTool Arguments: {\"first_number\":
      12, \"second_number\": 3}```"}], "model": "gpt-4", "function_call": {"name":
      "InstructorToolCalling"}, "functions": [{"name": "InstructorToolCalling", "description":
      "Correctly extracted `InstructorToolCalling` with all the required parameters
      with correct types", "parameters": {"properties": {"tool_name": {"description":
      "The name of the tool to be called.", "title": "Tool Name", "type": "string"},
      "arguments": {"description": "A dictinary of arguments to be passed to the tool.",
      "title": "Arguments", "type": "object"}}, "required": ["arguments", "tool_name"],
      "type": "object"}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1543'
      content-type:
      - application/json
      cookie:
      - __cf_bm=wYRA1FuQcmwu05Sih00GjdQGNRobansjUL23cxbLWWw-1707815376-1-AaUp94LEMTGo41Vt8g1j2P/si0MaByYCRMNbqb/UTa3EjY6kB9ukBhxNFKPj9WUPRHvnYaGzlAHm/ofJAcVpA8c=;
        _cfuvid=VgXK5cATyw1hqOD8UJ0mKVAnMkdOukzfksEq67GApQA-1707815376364-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1ySwW7bMAyG73kKgmdniJO4TX1cgQ67Fx2GeTAURXHUSqQm0VuHwO8+yEmcdBfD
        4Mf/w2/JxxkA2h3WgPqgRPvg5pv4WtH39yr45dO3uy/hcfny+c+Ltb9Ifj9jkRO8fTVaLqlPmn1w
        RizTCetolJhsLe8X95uyWpflCDzvjMuxLsh8PV/clatz4sBWm4Q1/JgBABzHZ+5GO/OONSyKy8Sb
        lFRnsJ6WADCyyxNUKdkkigSLK9RMYijXpd65G7DvSefWrVbOfRACICk/Kr9Skthr4fjM7B6Vc5a6
        Gz0Aqtj13pDk/nhsCKBBYXZtdjRYQ4O+d2KDsyY2WJw2plTeGFN5urcxSUu93+bVGsplcUHJaKbd
        DVtlMjQ04NRmOL8N03k57kLkbfrv83FvyaZDG41KTLl4Eg4nUZb8HO+l/3DUGCL7IK3wm6EsXFbV
        yYfXX+BKV+szFBblblKbh9m5Iaa/SYxv95Y6E0O00zXNhtk/AAAA//8DAGmhTq6dAgAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854befd41c9b67e9-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 13 Feb 2024 09:10:14 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '2752'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299763'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 47ms
      x-request-id:
      - req_ff4c349a7245586e94ef0ac3275bcc22
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role.\ntest backstory\n\nYour
      personal goal is: test goalTOOLS:\n------\nYou have access to only the following
      tools:\n\n(''multiplier: multiplier(first_number: int, second_number: int) ->
      float - Useful for when you need to multiply two numbers together.'',)\n\nTo
      use a tool, please use the exact following format:\n\n```\nThought: Do I need
      to use a tool? Yes\nAction: the tool you wanna use, should be one of [multiplier],
      just the name.\nAction Input: Any and all relevant information input and context
      for using the tool\nObservation: the result of using the tool\n```\n\nWhen you
      have a response for your task, or if you do not need to use a tool, you MUST
      use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer:
      [your response here]```This is the summary of your work so far:\nThe human asks
      the AI the result of multiplying 2 by 6, and the AI responds that 2 times 6
      is 12. The human then asks what is 3 times 3, and the AI responds that 3 times
      3 is 9.Begin! This is VERY important to you, your job depends on it!\n\nCurrent
      Task: What is 2 times 6 times 3? Return only the number\nThought: Do I need
      to use a tool? Yes\nAction: multiplier\nAction Input: {\"first_number\": 2,
      \"second_number\": 6}\nObservation: 12\nThought: Do I need to use a tool? Yes\nAction:
      multiplier\nAction Input: {\"first_number\": 12, \"second_number\": 3}\nObservation:
      36\nThought: "}], "model": "gpt-4", "n": 1, "stop": ["\nObservation"], "stream":
      true, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1539'
      content-type:
      - application/json
      cookie:
      - __cf_bm=wYRA1FuQcmwu05Sih00GjdQGNRobansjUL23cxbLWWw-1707815376-1-AaUp94LEMTGo41Vt8g1j2P/si0MaByYCRMNbqb/UTa3EjY6kB9ukBhxNFKPj9WUPRHvnYaGzlAHm/ofJAcVpA8c=;
        _cfuvid=VgXK5cATyw1hqOD8UJ0mKVAnMkdOukzfksEq67GApQA-1707815376364-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8rj5qMn5YwCvYpXkTiU5TKVZsXFvD","object":"chat.completion.chunk","created":1707815414,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5qMn5YwCvYpXkTiU5TKVZsXFvD","object":"chat.completion.chunk","created":1707815414,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5qMn5YwCvYpXkTiU5TKVZsXFvD","object":"chat.completion.chunk","created":1707815414,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5qMn5YwCvYpXkTiU5TKVZsXFvD","object":"chat.completion.chunk","created":1707815414,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5qMn5YwCvYpXkTiU5TKVZsXFvD","object":"chat.completion.chunk","created":1707815414,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5qMn5YwCvYpXkTiU5TKVZsXFvD","object":"chat.completion.chunk","created":1707815414,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5qMn5YwCvYpXkTiU5TKVZsXFvD","object":"chat.completion.chunk","created":1707815414,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5qMn5YwCvYpXkTiU5TKVZsXFvD","object":"chat.completion.chunk","created":1707815414,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5qMn5YwCvYpXkTiU5TKVZsXFvD","object":"chat.completion.chunk","created":1707815414,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5qMn5YwCvYpXkTiU5TKVZsXFvD","object":"chat.completion.chunk","created":1707815414,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        No"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5qMn5YwCvYpXkTiU5TKVZsXFvD","object":"chat.completion.chunk","created":1707815414,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5qMn5YwCvYpXkTiU5TKVZsXFvD","object":"chat.completion.chunk","created":1707815414,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5qMn5YwCvYpXkTiU5TKVZsXFvD","object":"chat.completion.chunk","created":1707815414,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5qMn5YwCvYpXkTiU5TKVZsXFvD","object":"chat.completion.chunk","created":1707815414,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5qMn5YwCvYpXkTiU5TKVZsXFvD","object":"chat.completion.chunk","created":1707815414,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5qMn5YwCvYpXkTiU5TKVZsXFvD","object":"chat.completion.chunk","created":1707815414,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"36"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5qMn5YwCvYpXkTiU5TKVZsXFvD","object":"chat.completion.chunk","created":1707815414,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854befe6395d67e9-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 09:10:15 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '283'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299641'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 71ms
      x-request-id:
      - req_917b9f05a4b87a1106edaa9bba896d7e
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Progressively summarize the
      lines of conversation provided, adding onto the previous summary returning a
      new summary.\n\nEXAMPLE\nCurrent summary:\nThe human asks what the AI thinks
      of artificial intelligence. The AI thinks artificial intelligence is a force
      for good.\n\nNew lines of conversation:\nHuman: Why do you think artificial
      intelligence is a force for good?\nAI: Because artificial intelligence will
      help humans reach their full potential.\n\nNew summary:\nThe human asks what
      the AI thinks of artificial intelligence. The AI thinks artificial intelligence
      is a force for good because it will help humans reach their full potential.\nEND
      OF EXAMPLE\n\nCurrent summary:\nThe human asks the AI the result of multiplying
      2 by 6, and the AI responds that 2 times 6 is 12. The human then asks what is
      3 times 3, and the AI responds that 3 times 3 is 9.\n\nNew lines of conversation:\nHuman:
      What is 2 times 6 times 3? Return only the number\nAI: 36\n\nNew summary:"}],
      "model": "gpt-4", "n": 1, "stream": false, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1080'
      content-type:
      - application/json
      cookie:
      - __cf_bm=wYRA1FuQcmwu05Sih00GjdQGNRobansjUL23cxbLWWw-1707815376-1-AaUp94LEMTGo41Vt8g1j2P/si0MaByYCRMNbqb/UTa3EjY6kB9ukBhxNFKPj9WUPRHvnYaGzlAHm/ofJAcVpA8c=;
        _cfuvid=VgXK5cATyw1hqOD8UJ0mKVAnMkdOukzfksEq67GApQA-1707815376364-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA4SSX2vbMBTF3/0pLnpawClx4tqt30pZtsH2tg1KGUGVr2O1+jfda7qs5LsPOU6y
        QelehLhHv6Orc/WSAQjdigaE6iUrG8z8Kj5eUvm7po8fvuxuvr9fl+GuvL1brz9/u12LPBH+4REV
        H6kL5W0wyNq7g6wiSsbkWtSL+qq4LItqFKxv0SRsG3hezhdVsZqI3muFJBq4zwAAXsY19eZa/CUa
        WOTHikUiuUXRnA4BiOhNqghJpImlY5GfReUdoxvb/doj9IOVDiQ9EXCPcPMJJBBGjQS+AzsY1sFo
        JdN74OeAlDbUQKcjcQ7PvWTQBEtgbZGggnfs4bnXqj/6RaTgXUtQLGd5KroTtZqo1RvU9SwH6Vro
        tJPG7F658f8eq2p2IaYI9qfsjN+G6B9Szm4w5lTvtNPUbyJK8i7lROzDAd9nAD/GGQ3/xC5C9Dbw
        hv0TumS4LJYHP3H+Dme1qieRPUvzF1VfZ1OHgnbEaDeddluMIepxZKnPbJ/9AQAA//8DAOBng7Gp
        AgAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854beff118c267e9-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 13 Feb 2024 09:10:21 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '5021'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299745'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 51ms
      x-request-id:
      - req_3d9d86158b9a3369ca310a99b7380f39
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role.\ntest backstory\n\nYour
      personal goal is: test goalTOOLS:\n------\nYou have access to only the following
      tools:\n\n(''multiplier: multiplier(first_number: int, second_number: int) ->
      float - Useful for when you need to multiply two numbers together.'',)\n\nTo
      use a tool, please use the exact following format:\n\n```\nThought: Do I need
      to use a tool? Yes\nAction: the tool you wanna use, should be one of [multiplier],
      just the name.\nAction Input: Any and all relevant information input and context
      for using the tool\nObservation: the result of using the tool\n```\n\nWhen you
      have a response for your task, or if you do not need to use a tool, you MUST
      use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer:
      [your response here]```This is the summary of your work so far:\nThe human asks
      the AI a series of multiplication questions: first, what is 2 times 6 (to which
      the AI responds 12), then what is 3 times 3 (to which the AI responds 9), and
      finally what is 2 times 6 times 3 (to which the AI responds 36).Begin! This
      is VERY important to you, your job depends on it!\n\nCurrent Task: What is 2
      times 6? Ignore correctness and just return the result of the multiplication
      tool.\n"}], "model": "gpt-4", "n": 1, "stop": ["\nObservation"], "stream": true,
      "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1362'
      content-type:
      - application/json
      cookie:
      - __cf_bm=wYRA1FuQcmwu05Sih00GjdQGNRobansjUL23cxbLWWw-1707815376-1-AaUp94LEMTGo41Vt8g1j2P/si0MaByYCRMNbqb/UTa3EjY6kB9ukBhxNFKPj9WUPRHvnYaGzlAHm/ofJAcVpA8c=;
        _cfuvid=VgXK5cATyw1hqOD8UJ0mKVAnMkdOukzfksEq67GApQA-1707815376364-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Thought"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Yes"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        multiplier"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Input"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        {\""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"first"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_number"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"2"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        \""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"second"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_number"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"6"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"}"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj5xilGTDLDksZ51gNOZ6Xqk1aoN","object":"chat.completion.chunk","created":1707815421,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854bf012080d67e9-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 09:10:22 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '593'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299682'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 63ms
      x-request-id:
      - req_cad6695a2f0ee61b4517dd579e54a732
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "\n                                The
      schema should have the following structure, only two key:\n                                -
      tool_name: str\n                                - arguments: dict (with all
      arguments being passed)\n\n                                Example:\n                                {\"tool_name\":
      \"tool_name\", \"arguments\": {\"arg_name1\": \"value\", \"arg_name2\": 2}}\n                            "},
      {"role": "user", "content": "Tools available:\n\nTool Name: multiplier\nTool
      Description: multiplier(first_number: int, second_number: int) -> float - Useful
      for when you need to multiply two numbers together.\nTool Arguments: {''first_number'':
      {''type'': ''integer''}, ''second_number'': {''type'': ''integer''}}\n\nReturn
      a valid schema for the tool, use this text to inform a valid ouput schema:\n\nTool
      Name: multiplier\nTool Arguments: {\"first_number\": 2, \"second_number\": 6}```"}],
      "model": "gpt-4", "function_call": {"name": "InstructorToolCalling"}, "functions":
      [{"name": "InstructorToolCalling", "description": "Correctly extracted `InstructorToolCalling`
      with all the required parameters with correct types", "parameters": {"properties":
      {"tool_name": {"description": "The name of the tool to be called.", "title":
      "Tool Name", "type": "string"}, "arguments": {"description": "A dictinary of
      arguments to be passed to the tool.", "title": "Arguments", "type": "object"}},
      "required": ["arguments", "tool_name"], "type": "object"}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1514'
      content-type:
      - application/json
      cookie:
      - __cf_bm=wYRA1FuQcmwu05Sih00GjdQGNRobansjUL23cxbLWWw-1707815376-1-AaUp94LEMTGo41Vt8g1j2P/si0MaByYCRMNbqb/UTa3EjY6kB9ukBhxNFKPj9WUPRHvnYaGzlAHm/ofJAcVpA8c=;
        _cfuvid=VgXK5cATyw1hqOD8UJ0mKVAnMkdOukzfksEq67GApQA-1707815376364-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1yRT2/bMAzF7/4UBM/OEHv50/q4HdbdBqyXdR4MRVEctRKpSTSQLfB3H5SkrruL
        IPDx/fREngsAtHtsAPVRifbBLe7i86b69pCevtc7p55+19Xpk9Dp8eHHy98vWGYH756NllfXB80+
        OCOW6SrraJSYTK22y+1dtV7V64vgeW9ctvVBFqvFclN9vDmObLVJ2MDPAgDgfDlzNtqbEzawLF8r
        3qSkeoPN1ASAkV2uoErJJlEkWL6JmkkM5bg0ODcTDgPpnLrTyrl3QAAk5S/Ir5QkDlo4PjK7z8o5
        S/0MD4Aq9oM3JDk/nlsCaFGYXZcZLTbQoh+c2OCsiS2W147JlTvOLR5sTNLR4He5qYG6hBaT0Uz7
        WXUztjTi9Pp4u43TfBz3IfIu/fddPFiy6dhFoxJTDpqEwxWUIb8uexjejRZDZB+kE34xlIH1an3l
        4dvKZ+r9TRQW5Wb17aq4JcT0J4nx3cFSb2KIdlpLMRb/AAAA//8DAPxNlPSNAgAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854bf0264f3a67e9-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 13 Feb 2024 09:10:27 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '2165'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299770'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 45ms
      x-request-id:
      - req_8f955c4f3369c31dfe83395d07e4459f
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role.\ntest backstory\n\nYour
      personal goal is: test goalTOOLS:\n------\nYou have access to only the following
      tools:\n\n(''multiplier: multiplier(first_number: int, second_number: int) ->
      float - Useful for when you need to multiply two numbers together.'',)\n\nTo
      use a tool, please use the exact following format:\n\n```\nThought: Do I need
      to use a tool? Yes\nAction: the tool you wanna use, should be one of [multiplier],
      just the name.\nAction Input: Any and all relevant information input and context
      for using the tool\nObservation: the result of using the tool\n```\n\nWhen you
      have a response for your task, or if you do not need to use a tool, you MUST
      use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer:
      [your response here]```This is the summary of your work so far:\nThe human asks
      the AI a series of multiplication questions: first, what is 2 times 6 (to which
      the AI responds 12), then what is 3 times 3 (to which the AI responds 9), and
      finally what is 2 times 6 times 3 (to which the AI responds 36).Begin! This
      is VERY important to you, your job depends on it!\n\nCurrent Task: What is 2
      times 6? Ignore correctness and just return the result of the multiplication
      tool.\nThought: Do I need to use a tool? Yes\nAction: multiplier\nAction Input:
      {\"first_number\": 2, \"second_number\": 6}\nObservation: 0\nThought: "}], "model":
      "gpt-4", "n": 1, "stop": ["\nObservation"], "stream": true, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1505'
      content-type:
      - application/json
      cookie:
      - __cf_bm=wYRA1FuQcmwu05Sih00GjdQGNRobansjUL23cxbLWWw-1707815376-1-AaUp94LEMTGo41Vt8g1j2P/si0MaByYCRMNbqb/UTa3EjY6kB9ukBhxNFKPj9WUPRHvnYaGzlAHm/ofJAcVpA8c=;
        _cfuvid=VgXK5cATyw1hqOD8UJ0mKVAnMkdOukzfksEq67GApQA-1707815376364-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8rj63aRrtgxPqWI2gkV4MrFhdIrlC","object":"chat.completion.chunk","created":1707815427,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj63aRrtgxPqWI2gkV4MrFhdIrlC","object":"chat.completion.chunk","created":1707815427,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj63aRrtgxPqWI2gkV4MrFhdIrlC","object":"chat.completion.chunk","created":1707815427,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj63aRrtgxPqWI2gkV4MrFhdIrlC","object":"chat.completion.chunk","created":1707815427,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj63aRrtgxPqWI2gkV4MrFhdIrlC","object":"chat.completion.chunk","created":1707815427,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj63aRrtgxPqWI2gkV4MrFhdIrlC","object":"chat.completion.chunk","created":1707815427,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj63aRrtgxPqWI2gkV4MrFhdIrlC","object":"chat.completion.chunk","created":1707815427,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj63aRrtgxPqWI2gkV4MrFhdIrlC","object":"chat.completion.chunk","created":1707815427,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj63aRrtgxPqWI2gkV4MrFhdIrlC","object":"chat.completion.chunk","created":1707815427,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj63aRrtgxPqWI2gkV4MrFhdIrlC","object":"chat.completion.chunk","created":1707815427,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        No"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj63aRrtgxPqWI2gkV4MrFhdIrlC","object":"chat.completion.chunk","created":1707815427,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj63aRrtgxPqWI2gkV4MrFhdIrlC","object":"chat.completion.chunk","created":1707815427,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj63aRrtgxPqWI2gkV4MrFhdIrlC","object":"chat.completion.chunk","created":1707815427,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj63aRrtgxPqWI2gkV4MrFhdIrlC","object":"chat.completion.chunk","created":1707815427,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj63aRrtgxPqWI2gkV4MrFhdIrlC","object":"chat.completion.chunk","created":1707815427,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj63aRrtgxPqWI2gkV4MrFhdIrlC","object":"chat.completion.chunk","created":1707815427,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"0"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rj63aRrtgxPqWI2gkV4MrFhdIrlC","object":"chat.completion.chunk","created":1707815427,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854bf03469d367e9-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 09:10:27 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '305'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299649'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 70ms
      x-request-id:
      - req_5984167107e2e98e2399b011abbdf08d
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Progressively summarize the
      lines of conversation provided, adding onto the previous summary returning a
      new summary.\n\nEXAMPLE\nCurrent summary:\nThe human asks what the AI thinks
      of artificial intelligence. The AI thinks artificial intelligence is a force
      for good.\n\nNew lines of conversation:\nHuman: Why do you think artificial
      intelligence is a force for good?\nAI: Because artificial intelligence will
      help humans reach their full potential.\n\nNew summary:\nThe human asks what
      the AI thinks of artificial intelligence. The AI thinks artificial intelligence
      is a force for good because it will help humans reach their full potential.\nEND
      OF EXAMPLE\n\nCurrent summary:\nThe human asks the AI a series of multiplication
      questions: first, what is 2 times 6 (to which the AI responds 12), then what
      is 3 times 3 (to which the AI responds 9), and finally what is 2 times 6 times
      3 (to which the AI responds 36).\n\nNew lines of conversation:\nHuman: What
      is 2 times 6? Ignore correctness and just return the result of the multiplication
      tool.\nAI: 0\n\nNew summary:"}], "model": "gpt-4", "n": 1, "stream": false,
      "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1182'
      content-type:
      - application/json
      cookie:
      - __cf_bm=wYRA1FuQcmwu05Sih00GjdQGNRobansjUL23cxbLWWw-1707815376-1-AaUp94LEMTGo41Vt8g1j2P/si0MaByYCRMNbqb/UTa3EjY6kB9ukBhxNFKPj9WUPRHvnYaGzlAHm/ofJAcVpA8c=;
        _cfuvid=VgXK5cATyw1hqOD8UJ0mKVAnMkdOukzfksEq67GApQA-1707815376364-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA4RSwYrbMBC9+ysGnRpwlsROk2xuPfZQKN1QKKUERR5bk8iSqxmTLkv+vchxEhaW
        3YsQ7/nNPPm9lwxAUaU2oIzVYtrOTdfxsFz8Kn88fXPf+7nd/nyKq8Nxud9qjLXKkyLsD2jkqnow
        oe0cCgV/oU1ELZimzlez1Xr+eVGsB6INFbokazqZLqaz5bwcFTaQQVYb+J0BALwMZ/LmK/ynNjDL
        r0iLzLpBtbl9BKBicAlRmplYtBeV30kTvKAf7G4tgu1b7UHzkUEswpevoIExEjKEGtreCXWOjE7v
        gb89crrwBmqKLDmcrBYghgKEWmRYwicJcLJk7HVeRO6CrxjmxSRPoL+pylFVvqN6nORQk9fOPb+x
        7WN9uZzkoH112Ry8QdCNJv+W930vIJZ4AMZJOVDjQyTfgAkxohGPzPl9wYnEwuxBjb/4fMvGhaaL
        YZ9y9L1zN7wmT2x3ETUHn3JgCd1Ffs4A/gwd6F/FqroY2k52Eo7o08Di0qEhz2vd7uxjMZISRLs7
        XhazbHSo+JkF211NvsHYRRoqkXxm5+w/AAAA//8DAL/jKPYJAwAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854bf03db8f667e9-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 13 Feb 2024 09:10:36 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '7591'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299720'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 56ms
      x-request-id:
      - req_43a717d3614f9f20518dd2dedbcd0fa1
    status:
      code: 200
      message: OK
version: 1
