interactions:
- request:
    body: !!binary |
      CuMLCiQKIgoMc2VydmljZS5uYW1lEhIKEGNyZXdBSS10ZWxlbWV0cnkSugsKEgoQY3Jld2FpLnRl
      bGVtZXRyeRKjCwoQEFjRIG2GoZQnrnnNcRe+MRIIGTM6Xe5biPAqDENyZXcgQ3JlYXRlZDABOUCG
      ovJ7XbMXQXg7pvJ7XbMXShoKDmNyZXdhaV92ZXJzaW9uEggKBjAuMTAuMkoaCg5weXRob25fdmVy
      c2lvbhIICgYzLjExLjdKMQoHY3Jld19pZBImCiQ5MmY3YTI0Zi03ZmE2LTQxNzgtYmIxYS02NDdm
      NTRjNzNkMDRKHAoMY3Jld19wcm9jZXNzEgwKCnNlcXVlbnRpYWxKFQoNY3Jld19sYW5ndWFnZRIE
      CgJlbkoaChRjcmV3X251bWJlcl9vZl90YXNrcxICGAJKGwoVY3Jld19udW1iZXJfb2ZfYWdlbnRz
      EgIYAkr9BAoLY3Jld19hZ2VudHMS7QQK6gRbeyJpZCI6ICIzOTFmYTliYy01ZTlmLTRiNDctYmIy
      Yy0xZjEwNjIxYWJkYjkiLCAicm9sZSI6ICJDRU8iLCAibWVtb3J5X2VuYWJsZWQ/IjogdHJ1ZSwg
      InZlcmJvc2U/IjogZmFsc2UsICJtYXhfaXRlciI6IDE1LCAibWF4X3JwbSI6IG51bGwsICJpMThu
      IjogImVuIiwgImxsbSI6ICJ7XCJuYW1lXCI6IG51bGwsIFwibW9kZWxfbmFtZVwiOiBcImdwdC00
      XCIsIFwidGVtcGVyYXR1cmVcIjogMC43LCBcImNsYXNzXCI6IFwiQ2hhdE9wZW5BSVwifSIsICJk
      ZWxlZ2F0aW9uX2VuYWJsZWQ/IjogdHJ1ZSwgInRvb2xzX25hbWVzIjogW119LCB7ImlkIjogImVm
      ODllOTZkLTkzMTUtNGRkOS1hYjhlLWZhZWI3ZTI0MDBhNCIsICJyb2xlIjogIlJlc2VhcmNoZXIi
      LCAibWVtb3J5X2VuYWJsZWQ/IjogdHJ1ZSwgInZlcmJvc2U/IjogZmFsc2UsICJtYXhfaXRlciI6
      IDE1LCAibWF4X3JwbSI6IG51bGwsICJpMThuIjogImVuIiwgImxsbSI6ICJ7XCJuYW1lXCI6IG51
      bGwsIFwibW9kZWxfbmFtZVwiOiBcImdwdC00XCIsIFwidGVtcGVyYXR1cmVcIjogMC43LCBcImNs
      YXNzXCI6IFwiQ2hhdE9wZW5BSVwifSIsICJkZWxlZ2F0aW9uX2VuYWJsZWQ/IjogZmFsc2UsICJ0
      b29sc19uYW1lcyI6IFtdfV1KlwIKCmNyZXdfdGFza3MSiAIKhQJbeyJpZCI6ICI0Y2NmOWVkYS02
      OWEyLTQ5NmItOTI5Zi0yMTQ4NDBkMDdhYjQiLCAiYXN5bmNfZXhlY3V0aW9uPyI6IGZhbHNlLCAi
      YWdlbnRfcm9sZSI6ICJDRU8iLCAidG9vbHNfbmFtZXMiOiBbIm11bHRpcGxpZXIiXX0sIHsiaWQi
      OiAiZDU5Nzg0MmItYzE4Mi00YTY2LTgwYjItNzdlYzM4MjRhOTYxIiwgImFzeW5jX2V4ZWN1dGlv
      bj8iOiBmYWxzZSwgImFnZW50X3JvbGUiOiAiUmVzZWFyY2hlciIsICJ0b29sc19uYW1lcyI6IFsi
      bXVsdGlwbGllciJdfV1KKAoIcGxhdGZvcm0SHAoabWFjT1MtMTQuMy1hcm02NC1hcm0tNjRiaXRK
      HAoQcGxhdGZvcm1fcmVsZWFzZRIICgYyMy4zLjBKGwoPcGxhdGZvcm1fc3lzdGVtEggKBkRhcndp
      bkp7ChBwbGF0Zm9ybV92ZXJzaW9uEmcKZURhcndpbiBLZXJuZWwgVmVyc2lvbiAyMy4zLjA6IFdl
      ZCBEZWMgMjAgMjE6MzA6NTkgUFNUIDIwMjM7IHJvb3Q6eG51LTEwMDAyLjgxLjV+Ny9SRUxFQVNF
      X0FSTTY0X1Q2MDMwSgoKBGNwdXMSAhgMegIYAQ==
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '1510'
      Content-Type:
      - application/x-protobuf
      User-Agent:
      - OTel-OTLP-Exporter-Python/1.22.0
    method: POST
    uri: http://telemetry.crewai.com:4318/v1/traces
  response:
    body:
      string: "\n\0"
    headers:
      Content-Length:
      - '2'
      Content-Type:
      - application/x-protobuf
      Date:
      - Tue, 13 Feb 2024 08:04:31 GMT
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are CEO.\nYou''re an long
      time CEO of a content creation agency with a Senior Writer on the team. You''re
      now working on a new project and want to make sure the content produced is amazing.\n\nYour
      personal goal is: Make sure the writers in your company produce amazing content.TOOLS:\n------\nYou
      have access to only the following tools:\n\n(\"multiplier: multiplier(first_number:
      int, second_number: int) -> float - Useful for when you need to multiply two
      numbers together.\\nDelegate work to co-worker: Delegate work to co-worker(coworker:
      str, task: str, context: str) - Delegate a specific task to one of the following
      co-workers:\\n- Researcher.\\nThe input to this tool should be the role of the
      coworker, the task you want them to do, and ALL necessary context to exectue
      the task, they know nothing about the task, so share absolute everything you
      know, don''t reference things but instead explain them.\\nAsk question to co-worker:
      Ask question to co-worker(coworker: str, question: str, context: str) - Ask
      a specific question to one of the following co-workers:\\n- Researcher.\\nThe
      input to this tool should be the role of the coworker, the question you have
      for them, and ALL necessary context to ask the question properly, they know
      nothing about the question, so share absolute everything you know, don''t reference
      things but instead explain them.\",)\n\nTo use a tool, please use the exact
      following format:\n\n```\nThought: Do I need to use a tool? Yes\nAction: the
      tool you wanna use, should be one of [multiplier, Delegate work to co-worker,
      Ask question to co-worker], just the name.\nAction Input: Any and all relevant
      information input and context for using the tool\nObservation: the result of
      using the tool\n```\n\nWhen you have a response for your task, or if you do
      not need to use a tool, you MUST use the format:\n\n```\nThought: Do I need
      to use a tool? No\nFinal Answer: [your response here]```This is the summary
      of your work so far:\nBegin! This is VERY important to you, your job depends
      on it!\n\nCurrent Task: What is 2 tims 6? Return only the number.\n"}], "model":
      "gpt-4", "n": 1, "stop": ["\nObservation"], "stream": true, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2229'
      content-type:
      - application/json
      cookie:
      - __cf_bm=l8PgzrDOifuVgV8jOi6oNnLSKwzNw5zlnYEI_Qslu_o-1707811118-1-ARSm0+dQEO1vsfbM09g4mKX7cyvA/8odsM47nu2fWyCii5R/qlesVg08eZDiacndSQlL+nEfI/ne5RvoyPTGkgg=;
        _cfuvid=zFH17OERRVf.0CqqO0vUy7WbuquH88772m3kfb_dIbs-1707811118866-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Thought"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Yes"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        multiplier"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Input"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        {\""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"first"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_number"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"2"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        \""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"second"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_number"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"6"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"}"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4Ewek9ChNFjqPnJ9Q9SH7cC4eJ","object":"chat.completion.chunk","created":1707811470,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854b8f9ce8c567df-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 08:04:31 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '721'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299468'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 106ms
      x-request-id:
      - req_1ced6142eab0985809db866365f81b5e
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "\n                                The
      schema should have the following structure, only two key:\n                                -
      tool_name: str\n                                - arguments: dict (with all
      arguments being passed)\n\n                                Example:\n                                {\"tool_name\":
      \"tool_name\", \"arguments\": {\"arg_name1\": \"value\", \"arg_name2\": 2}}\n                            "},
      {"role": "user", "content": "Tools available:\n\nTool Name: multiplier\nTool
      Description: multiplier(first_number: int, second_number: int) -> float - Useful
      for when you need to multiply two numbers together.\nTool Arguments: {''first_number'':
      {''type'': ''integer''}, ''second_number'': {''type'': ''integer''}}\n--\nTool
      Name: delegate work to co-worker\nTool Description: Delegate work to co-worker(coworker:
      str, task: str, context: str) - Delegate a specific task to one of the following
      co-workers:\n- Researcher.\nThe input to this tool should be the role of the
      coworker, the task you want them to do, and ALL necessary context to exectue
      the task, they know nothing about the task, so share absolute everything you
      know, don''t reference things but instead explain them.\nTool Arguments: {''coworker'':
      {''type'': ''string''}, ''task'': {''type'': ''string''}, ''context'': {''type'':
      ''string''}}\n--\nTool Name: ask question to co-worker\nTool Description: Ask
      question to co-worker(coworker: str, question: str, context: str) - Ask a specific
      question to one of the following co-workers:\n- Researcher.\nThe input to this
      tool should be the role of the coworker, the question you have for them, and
      ALL necessary context to ask the question properly, they know nothing about
      the question, so share absolute everything you know, don''t reference things
      but instead explain them.\nTool Arguments: {''coworker'': {''type'': ''string''},
      ''question'': {''type'': ''string''}, ''context'': {''type'': ''string''}}\n\nReturn
      a valid schema for the tool, use this text to inform a valid ouput schema:\n\nTool
      Name: multiplier\nTool Arguments: {\"first_number\": 2, \"second_number\": 6}```"}],
      "model": "gpt-4", "function_call": {"name": "InstructorToolCalling"}, "functions":
      [{"name": "InstructorToolCalling", "description": "Correctly extracted `InstructorToolCalling`
      with all the required parameters with correct types", "parameters": {"properties":
      {"tool_name": {"description": "The name of the tool to be called.", "title":
      "Tool Name", "type": "string"}, "arguments": {"description": "A dictinary of
      arguments to be passed to the tool.", "title": "Arguments", "type": "object"}},
      "required": ["arguments", "tool_name"], "type": "object"}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2684'
      content-type:
      - application/json
      cookie:
      - __cf_bm=l8PgzrDOifuVgV8jOi6oNnLSKwzNw5zlnYEI_Qslu_o-1707811118-1-ARSm0+dQEO1vsfbM09g4mKX7cyvA/8odsM47nu2fWyCii5R/qlesVg08eZDiacndSQlL+nEfI/ne5RvoyPTGkgg=;
        _cfuvid=zFH17OERRVf.0CqqO0vUy7WbuquH88772m3kfb_dIbs-1707811118866-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1yRQW/bMAyF7/4VAs/OEHdu0vraXXodil3mwZAVxtFGkZ5EoysC//dBSeqkvQgC
        H9+nJ/JYGAN+B40Bd7Dqwkirh+jr56d7eq2p+vHt73fs9W16PLz0r+teoMwO6X+j03fXFydhJFQv
        fJZdRKuYqdV2vX2oqnpbn4QgO6RsG0Zd1av1pvp6cRzEO0zQmJ+FMcYcT2fOxjv8B41Zl++VgCnZ
        AaFZmoyBKJQrYFPySS0rlFfRCStyjssT0Y2wn9jl1J2zRB+AxgDbcEI+c9I4OZX4IkJPlsjzcIM3
        BmwcpoCsOT8cW25BRajLhBYa00KYSP1IHmMLZdYXR9aPLex9TNrxFPrc0pi70rSQ0AnvbqqbueUZ
        lpfny21eZkMyjFH69OmrsPfs06GLaJNwDplUxjMoQ36ddjB9GCuMUcKoncof5Ay8rx7PPLiu+6re
        bS+iilq6cdWb4pIQ0ltSDN3e84BxjH5ZSTEX/wEAAP//AwDUPpRQiQIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854b8fb10ca067df-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 13 Feb 2024 08:04:36 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '2043'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299480'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 103ms
      x-request-id:
      - req_bca5e146f656c30dcb843a85773b3f27
    status:
      code: 200
      message: OK
- request:
    body: !!binary |
      CoYCCiQKIgoMc2VydmljZS5uYW1lEhIKEGNyZXdBSS10ZWxlbWV0cnkS3QEKEgoQY3Jld2FpLnRl
      bGVtZXRyeRLGAQoQqmwdnIY5wuObfEdb+dRqvxIIeMSfUAOIjG4qClRvb2wgVXNhZ2UwATkQ/rVA
      fV2zF0GIYbdAfV2zF0oZCgl0b29sX25hbWUSDAoKbXVsdGlwbGllckoOCghhdHRlbXB0cxICGAFK
      WQoDbGxtElIKUHsibmFtZSI6IG51bGwsICJtb2RlbF9uYW1lIjogImdwdC00IiwgInRlbXBlcmF0
      dXJlIjogMC43LCAiY2xhc3MiOiAiQ2hhdE9wZW5BSSJ9egIYAQ==
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '265'
      Content-Type:
      - application/x-protobuf
      User-Agent:
      - OTel-OTLP-Exporter-Python/1.22.0
    method: POST
    uri: http://telemetry.crewai.com:4318/v1/traces
  response:
    body:
      string: "\n\0"
    headers:
      Content-Length:
      - '2'
      Content-Type:
      - application/x-protobuf
      Date:
      - Tue, 13 Feb 2024 08:04:36 GMT
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are CEO.\nYou''re an long
      time CEO of a content creation agency with a Senior Writer on the team. You''re
      now working on a new project and want to make sure the content produced is amazing.\n\nYour
      personal goal is: Make sure the writers in your company produce amazing content.TOOLS:\n------\nYou
      have access to only the following tools:\n\n(\"multiplier: multiplier(first_number:
      int, second_number: int) -> float - Useful for when you need to multiply two
      numbers together.\\nDelegate work to co-worker: Delegate work to co-worker(coworker:
      str, task: str, context: str) - Delegate a specific task to one of the following
      co-workers:\\n- Researcher.\\nThe input to this tool should be the role of the
      coworker, the task you want them to do, and ALL necessary context to exectue
      the task, they know nothing about the task, so share absolute everything you
      know, don''t reference things but instead explain them.\\nAsk question to co-worker:
      Ask question to co-worker(coworker: str, question: str, context: str) - Ask
      a specific question to one of the following co-workers:\\n- Researcher.\\nThe
      input to this tool should be the role of the coworker, the question you have
      for them, and ALL necessary context to ask the question properly, they know
      nothing about the question, so share absolute everything you know, don''t reference
      things but instead explain them.\",)\n\nTo use a tool, please use the exact
      following format:\n\n```\nThought: Do I need to use a tool? Yes\nAction: the
      tool you wanna use, should be one of [multiplier, Delegate work to co-worker,
      Ask question to co-worker], just the name.\nAction Input: Any and all relevant
      information input and context for using the tool\nObservation: the result of
      using the tool\n```\n\nWhen you have a response for your task, or if you do
      not need to use a tool, you MUST use the format:\n\n```\nThought: Do I need
      to use a tool? No\nFinal Answer: [your response here]```This is the summary
      of your work so far:\nBegin! This is VERY important to you, your job depends
      on it!\n\nCurrent Task: What is 2 tims 6? Return only the number.\nThought:
      Do I need to use a tool? Yes\nAction: multiplier\nAction Input: {\"first_number\":
      2, \"second_number\": 6}\nObservation: 12\nThought: "}], "model": "gpt-4", "n":
      1, "stop": ["\nObservation"], "stream": true, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2373'
      content-type:
      - application/json
      cookie:
      - __cf_bm=l8PgzrDOifuVgV8jOi6oNnLSKwzNw5zlnYEI_Qslu_o-1707811118-1-ARSm0+dQEO1vsfbM09g4mKX7cyvA/8odsM47nu2fWyCii5R/qlesVg08eZDiacndSQlL+nEfI/ne5RvoyPTGkgg=;
        _cfuvid=zFH17OERRVf.0CqqO0vUy7WbuquH88772m3kfb_dIbs-1707811118866-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8ri4KWNfT7nXicmycukCk1Z0tfFz0","object":"chat.completion.chunk","created":1707811476,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4KWNfT7nXicmycukCk1Z0tfFz0","object":"chat.completion.chunk","created":1707811476,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4KWNfT7nXicmycukCk1Z0tfFz0","object":"chat.completion.chunk","created":1707811476,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4KWNfT7nXicmycukCk1Z0tfFz0","object":"chat.completion.chunk","created":1707811476,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4KWNfT7nXicmycukCk1Z0tfFz0","object":"chat.completion.chunk","created":1707811476,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4KWNfT7nXicmycukCk1Z0tfFz0","object":"chat.completion.chunk","created":1707811476,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4KWNfT7nXicmycukCk1Z0tfFz0","object":"chat.completion.chunk","created":1707811476,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4KWNfT7nXicmycukCk1Z0tfFz0","object":"chat.completion.chunk","created":1707811476,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4KWNfT7nXicmycukCk1Z0tfFz0","object":"chat.completion.chunk","created":1707811476,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4KWNfT7nXicmycukCk1Z0tfFz0","object":"chat.completion.chunk","created":1707811476,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        No"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4KWNfT7nXicmycukCk1Z0tfFz0","object":"chat.completion.chunk","created":1707811476,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4KWNfT7nXicmycukCk1Z0tfFz0","object":"chat.completion.chunk","created":1707811476,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4KWNfT7nXicmycukCk1Z0tfFz0","object":"chat.completion.chunk","created":1707811476,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4KWNfT7nXicmycukCk1Z0tfFz0","object":"chat.completion.chunk","created":1707811476,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4KWNfT7nXicmycukCk1Z0tfFz0","object":"chat.completion.chunk","created":1707811476,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4KWNfT7nXicmycukCk1Z0tfFz0","object":"chat.completion.chunk","created":1707811476,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"12"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4KWNfT7nXicmycukCk1Z0tfFz0","object":"chat.completion.chunk","created":1707811476,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854b8fbed8b167df-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 08:04:41 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '4552'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299434'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 113ms
      x-request-id:
      - req_664919380e69086067c3ddcd59030830
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Progressively summarize the
      lines of conversation provided, adding onto the previous summary returning a
      new summary.\n\nEXAMPLE\nCurrent summary:\nThe human asks what the AI thinks
      of artificial intelligence. The AI thinks artificial intelligence is a force
      for good.\n\nNew lines of conversation:\nHuman: Why do you think artificial
      intelligence is a force for good?\nAI: Because artificial intelligence will
      help humans reach their full potential.\n\nNew summary:\nThe human asks what
      the AI thinks of artificial intelligence. The AI thinks artificial intelligence
      is a force for good because it will help humans reach their full potential.\nEND
      OF EXAMPLE\n\nCurrent summary:\n\n\nNew lines of conversation:\nHuman: What
      is 2 tims 6? Return only the number.\nAI: 12\n\nNew summary:"}], "model": "gpt-4",
      "n": 1, "stream": false, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '895'
      content-type:
      - application/json
      cookie:
      - __cf_bm=l8PgzrDOifuVgV8jOi6oNnLSKwzNw5zlnYEI_Qslu_o-1707811118-1-ARSm0+dQEO1vsfbM09g4mKX7cyvA/8odsM47nu2fWyCii5R/qlesVg08eZDiacndSQlL+nEfI/ne5RvoyPTGkgg=;
        _cfuvid=zFH17OERRVf.0CqqO0vUy7WbuquH88772m3kfb_dIbs-1707811118866-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1SQS09CMRCF9/dXTLoGwkVessOdiYlEjRiNIaV35FbaTtMZREP476aXl266OGfO
        9JuzKwCUrdQElKm1GB9de5xs/6H7OuPx7Q0P5/PH6afc3331/Oxl8KxaOUHLTzRySnUM+ehQLIWD
        bRJqwby1HHVH47Lsj68aw1OFLsdWUdr9dndYXh0TNVmDrCbwVgAA7Jo3s4UKv9UEuq2T4pFZr1BN
        zkMAKpHLitLMlkUHUa2LaSgIhgb3qUaoN14H0LxmkBphegtCYLQzG6cFoQdiPTIMQYfqNJGQI4WK
        YWulbkRDKaER0IG3mFpQ9jrq+OX+zOpoFRMt811h49xZ/7DBcr1IqJlC5mKheIjvC4D3ppPNvzNV
        TOSjLITWGPLCcjA47FOX+i9ur380hUS7P6nRdXEkVPzDgn7xYcMKU0y2qShzFvviFwAA//8DAKzL
        eCUZAgAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854b8feb99cf67df-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 13 Feb 2024 08:04:45 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '1585'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299792'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 41ms
      x-request-id:
      - req_cf6bd3745d661d1a06f8e77ba41a6e3c
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are Researcher.\nYou''re
      an expert researcher, specialized in technology, software engineering, AI and
      startups. You work as a freelancer and is now working on doing research and
      analysis for a new customer.\n\nYour personal goal is: Make the best research
      and analysis on content about AI and AI agentsTOOLS:\n------\nYou have access
      to only the following tools:\n\n(''multiplier: multiplier(first_number: int,
      second_number: int) -> float - Useful for when you need to multiply two numbers
      together.'',)\n\nTo use a tool, please use the exact following format:\n\n```\nThought:
      Do I need to use a tool? Yes\nAction: the tool you wanna use, should be one
      of [multiplier], just the name.\nAction Input: Any and all relevant information
      input and context for using the tool\nObservation: the result of using the tool\n```\n\nWhen
      you have a response for your task, or if you do not need to use a tool, you
      MUST use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer:
      [your response here]```This is the summary of your work so far:\nBegin! This
      is VERY important to you, your job depends on it!\n\nCurrent Task: What is 2
      times 6? Return only the number.\nThis is the context you''re working with:\n12\n"}],
      "model": "gpt-4", "n": 1, "stop": ["\nObservation"], "stream": true, "temperature":
      0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1357'
      content-type:
      - application/json
      cookie:
      - __cf_bm=2Sq6QZC8ubo0uaJ_oGz9MIc.QFOOBbArVVZ1hfDyGmY-1707810872-1-AY/zSUU/W0R+ddbwbB8c9lfjiRTZgncqZIx1TKFkrJ39ZvX/bciOo1iWiRtqop2nD6+FnZ84Mc82Pq09fbaL5k4=;
        _cfuvid=KRcEIDH8_CjxRUfnBClhnKowC8izvirPV4maDe0gpuk-1707810872815-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Thought"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Yes"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        multiplier"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Input"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        {''"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"first"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_number"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"'':"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"2"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        ''"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"second"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_number"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"'':"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"6"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"}"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4TnQAwS2Mkvt0VJmbBQ5cOfOm8","object":"chat.completion.chunk","created":1707811485,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854b8ff6efe096cc-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 08:04:45 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '379'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299684'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 63ms
      x-request-id:
      - req_f95479368c97322e2ddfd0fe147b41b1
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "\n                                The
      schema should have the following structure, only two key:\n                                -
      tool_name: str\n                                - arguments: dict (with all
      arguments being passed)\n\n                                Example:\n                                {\"tool_name\":
      \"tool_name\", \"arguments\": {\"arg_name1\": \"value\", \"arg_name2\": 2}}\n                            "},
      {"role": "user", "content": "Tools available:\n\nTool Name: multiplier\nTool
      Description: multiplier(first_number: int, second_number: int) -> float - Useful
      for when you need to multiply two numbers together.\nTool Arguments: {''first_number'':
      {''type'': ''integer''}, ''second_number'': {''type'': ''integer''}}\n\nReturn
      a valid schema for the tool, use this text to inform a valid ouput schema:\n\nTool
      Name: multiplier\nTool Arguments: {''first_number'': 2, ''second_number'': 6}```"}],
      "model": "gpt-4", "function_call": {"name": "InstructorToolCalling"}, "functions":
      [{"name": "InstructorToolCalling", "description": "Correctly extracted `InstructorToolCalling`
      with all the required parameters with correct types", "parameters": {"properties":
      {"tool_name": {"description": "The name of the tool to be called.", "title":
      "Tool Name", "type": "string"}, "arguments": {"description": "A dictinary of
      arguments to be passed to the tool.", "title": "Arguments", "type": "object"}},
      "required": ["arguments", "tool_name"], "type": "object"}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1510'
      content-type:
      - application/json
      cookie:
      - __cf_bm=2Sq6QZC8ubo0uaJ_oGz9MIc.QFOOBbArVVZ1hfDyGmY-1707810872-1-AY/zSUU/W0R+ddbwbB8c9lfjiRTZgncqZIx1TKFkrJ39ZvX/bciOo1iWiRtqop2nD6+FnZ84Mc82Pq09fbaL5k4=;
        _cfuvid=KRcEIDH8_CjxRUfnBClhnKowC8izvirPV4maDe0gpuk-1707810872815-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1ySTYvbMBCG7/4Vw5ydkuy6SdbH7aFsYSmUQgt1MYqiOOpKM6o03g+C/3uRkzjZ
        XoyZZ96H15IPBQDaLdaAeq9E++Bm62irn/fLN702j+71y/2zV982L+6x+vz3x1csc4I3f4yWc+qD
        Zh+cEct0xDoaJSZbF6v5ar1YVOu7EXjeGpdjXZBZNZsvF7enxJ6tNglr+FUAABzGZ+5GW/OKNczL
        88SblFRnsJ6WADCyyxNUKdkkigTLC9RMYijXpd65K7DrSefWrVbOvRMCICk/Kh8oSey1cPzO7D4p
        5yx1V3oAVLHrvSHJ/fHQEECDwuza7GiwhgZ978QGZ01ssDxuTKm8MabydGdjkpZ6v8mrNdyUZ5KM
        ZtpeoWUmQ0MDTmWG09swHZfjLkTepP++HneWbNq30ajElHsn4XAUZcnv8Vr6dyeNIbIP0go/GcrC
        m+rj0YeXP+BCb6sTFBblrlKru+LUENNbEuPbnaXOxBDtdEvFUPwDAAD//wMAUqXvrJwCAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854b900e4c8496cc-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 13 Feb 2024 08:04:51 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '2787'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299770'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 45ms
      x-request-id:
      - req_7b9e983ec622f4bd47c4bce3724a4bc4
    status:
      code: 200
      message: OK
- request:
    body: !!binary |
      CoYCCiQKIgoMc2VydmljZS5uYW1lEhIKEGNyZXdBSS10ZWxlbWV0cnkS3QEKEgoQY3Jld2FpLnRl
      bGVtZXRyeRLGAQoQojieAZxEKElkA5qp0J4DzxII7FelX11TOuMqClRvb2wgVXNhZ2UwATkoy1Lj
      gF2zF0EQRlTjgF2zF0oZCgl0b29sX25hbWUSDAoKbXVsdGlwbGllckoOCghhdHRlbXB0cxICGAFK
      WQoDbGxtElIKUHsibmFtZSI6IG51bGwsICJtb2RlbF9uYW1lIjogImdwdC00IiwgInRlbXBlcmF0
      dXJlIjogMC43LCAiY2xhc3MiOiAiQ2hhdE9wZW5BSSJ9egIYAQ==
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '265'
      Content-Type:
      - application/x-protobuf
      User-Agent:
      - OTel-OTLP-Exporter-Python/1.22.0
    method: POST
    uri: http://telemetry.crewai.com:4318/v1/traces
  response:
    body:
      string: "\n\0"
    headers:
      Content-Length:
      - '2'
      Content-Type:
      - application/x-protobuf
      Date:
      - Tue, 13 Feb 2024 08:04:51 GMT
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are Researcher.\nYou''re
      an expert researcher, specialized in technology, software engineering, AI and
      startups. You work as a freelancer and is now working on doing research and
      analysis for a new customer.\n\nYour personal goal is: Make the best research
      and analysis on content about AI and AI agentsTOOLS:\n------\nYou have access
      to only the following tools:\n\n(''multiplier: multiplier(first_number: int,
      second_number: int) -> float - Useful for when you need to multiply two numbers
      together.'',)\n\nTo use a tool, please use the exact following format:\n\n```\nThought:
      Do I need to use a tool? Yes\nAction: the tool you wanna use, should be one
      of [multiplier], just the name.\nAction Input: Any and all relevant information
      input and context for using the tool\nObservation: the result of using the tool\n```\n\nWhen
      you have a response for your task, or if you do not need to use a tool, you
      MUST use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer:
      [your response here]```This is the summary of your work so far:\nBegin! This
      is VERY important to you, your job depends on it!\n\nCurrent Task: What is 2
      times 6? Return only the number.\nThis is the context you''re working with:\n12\nThought:
      Do I need to use a tool? Yes\nAction: multiplier\nAction Input: {''first_number'':
      2, ''second_number'': 6}\nObservation: 12\nThought: "}], "model": "gpt-4", "n":
      1, "stop": ["\nObservation"], "stream": true, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1497'
      content-type:
      - application/json
      cookie:
      - __cf_bm=2Sq6QZC8ubo0uaJ_oGz9MIc.QFOOBbArVVZ1hfDyGmY-1707810872-1-AY/zSUU/W0R+ddbwbB8c9lfjiRTZgncqZIx1TKFkrJ39ZvX/bciOo1iWiRtqop2nD6+FnZ84Mc82Pq09fbaL5k4=;
        _cfuvid=KRcEIDH8_CjxRUfnBClhnKowC8izvirPV4maDe0gpuk-1707810872815-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8ri4ZZBMrxW6UHWAorsLYoPmAhygi","object":"chat.completion.chunk","created":1707811491,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4ZZBMrxW6UHWAorsLYoPmAhygi","object":"chat.completion.chunk","created":1707811491,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4ZZBMrxW6UHWAorsLYoPmAhygi","object":"chat.completion.chunk","created":1707811491,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4ZZBMrxW6UHWAorsLYoPmAhygi","object":"chat.completion.chunk","created":1707811491,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4ZZBMrxW6UHWAorsLYoPmAhygi","object":"chat.completion.chunk","created":1707811491,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4ZZBMrxW6UHWAorsLYoPmAhygi","object":"chat.completion.chunk","created":1707811491,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4ZZBMrxW6UHWAorsLYoPmAhygi","object":"chat.completion.chunk","created":1707811491,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4ZZBMrxW6UHWAorsLYoPmAhygi","object":"chat.completion.chunk","created":1707811491,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4ZZBMrxW6UHWAorsLYoPmAhygi","object":"chat.completion.chunk","created":1707811491,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4ZZBMrxW6UHWAorsLYoPmAhygi","object":"chat.completion.chunk","created":1707811491,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        No"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4ZZBMrxW6UHWAorsLYoPmAhygi","object":"chat.completion.chunk","created":1707811491,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4ZZBMrxW6UHWAorsLYoPmAhygi","object":"chat.completion.chunk","created":1707811491,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4ZZBMrxW6UHWAorsLYoPmAhygi","object":"chat.completion.chunk","created":1707811491,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4ZZBMrxW6UHWAorsLYoPmAhygi","object":"chat.completion.chunk","created":1707811491,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4ZZBMrxW6UHWAorsLYoPmAhygi","object":"chat.completion.chunk","created":1707811491,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4ZZBMrxW6UHWAorsLYoPmAhygi","object":"chat.completion.chunk","created":1707811491,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"12"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8ri4ZZBMrxW6UHWAorsLYoPmAhygi","object":"chat.completion.chunk","created":1707811491,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854b90206dc796cc-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 08:04:52 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '386'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299650'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 70ms
      x-request-id:
      - req_0946b5813aa5a9b4d743bc1c4c67b705
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Progressively summarize the
      lines of conversation provided, adding onto the previous summary returning a
      new summary.\n\nEXAMPLE\nCurrent summary:\nThe human asks what the AI thinks
      of artificial intelligence. The AI thinks artificial intelligence is a force
      for good.\n\nNew lines of conversation:\nHuman: Why do you think artificial
      intelligence is a force for good?\nAI: Because artificial intelligence will
      help humans reach their full potential.\n\nNew summary:\nThe human asks what
      the AI thinks of artificial intelligence. The AI thinks artificial intelligence
      is a force for good because it will help humans reach their full potential.\nEND
      OF EXAMPLE\n\nCurrent summary:\n\n\nNew lines of conversation:\nHuman: What
      is 2 times 6? Return only the number.\nThis is the context you''re working with:\n12\nAI:
      12\n\nNew summary:"}], "model": "gpt-4", "n": 1, "stream": false, "temperature":
      0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '942'
      content-type:
      - application/json
      cookie:
      - __cf_bm=2Sq6QZC8ubo0uaJ_oGz9MIc.QFOOBbArVVZ1hfDyGmY-1707810872-1-AY/zSUU/W0R+ddbwbB8c9lfjiRTZgncqZIx1TKFkrJ39ZvX/bciOo1iWiRtqop2nD6+FnZ84Mc82Pq09fbaL5k4=;
        _cfuvid=KRcEIDH8_CjxRUfnBClhnKowC8izvirPV4maDe0gpuk-1707810872815-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1SQT08CMRDF7/spJj0vhAUE2ZsHNSQe1BgvxpDSHXYr3U7TGQRD+O6myz+99PDe
        vNffzD4DULZSJSjTaDFtcL3baMdL45euGNUvuwk/PM3v33eP38XzazNSeUrQ8guNnFN9Q21wKJb8
        0TYRtWBqLaaD6W1RjGejzmipQpdidZDeuDeYFKdC05A1yKqEjwwAYN+9ic1XuFMlDPKz0iKzrlGV
        lyEAFcklRWlmy6K9qPxqGvKCvsN9axCaTas9aF4zSINwNwchMNqZjdOCMASxLTJMctC+Oo9E5EC+
        YthaaTrRUIxoBLTnLcYcimFfnf48XGAd1SHSMi3mN85d9JX1lptFRM3kExgLhWP8kAF8dkfZ/NtT
        hUhtkIXQGn0qLCY3xz51vf/VHZ5NIdHuT2o2yE6Ein9YsF2srK8xhmi7GyXO7JD9AgAA//8DAL4I
        yp4aAgAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854b902afb4a96cc-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 13 Feb 2024 08:04:55 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '1725'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299780'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 44ms
      x-request-id:
      - req_e3e38104372c86a5698a119edda5c9be
    status:
      code: 200
      message: OK
version: 1
