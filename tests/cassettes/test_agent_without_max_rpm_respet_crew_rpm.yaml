interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role.\ntest backstory\n\nYour
      personal goal is: test goalTOOLS:\n------\nYou have access to only the following
      tools:\n\n(\"Delegate work to co-worker: Delegate work to co-worker(coworker:
      str, task: str, context: str) - Delegate a specific task to one of the following
      co-workers:\\n- test role2.\\nThe input to this tool should be the role of the
      coworker, the task you want them to do, and ALL necessary context to exectue
      the task, they know nothing about the task, so share absolute everything you
      know, don''t reference things but instead explain them.\\nAsk question to co-worker:
      Ask question to co-worker(coworker: str, question: str, context: str) - Ask
      a specific question to one of the following co-workers:\\n- test role2.\\nThe
      input to this tool should be the role of the coworker, the question you have
      for them, and ALL necessary context to ask the question properly, they know
      nothing about the question, so share absolute everything you know, don''t reference
      things but instead explain them.\",)\n\nTo use a tool, please use the exact
      following format:\n\n```\nThought: Do I need to use a tool? Yes\nAction: the
      tool you wanna use, should be one of [Delegate work to co-worker, Ask question
      to co-worker], just the name.\nAction Input: Any and all relevant information
      input and context for using the tool\nObservation: the result of using the tool\n```\n\nWhen
      you have a response for your task, or if you do not need to use a tool, you
      MUST use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer:
      [your response here]```This is the summary of your work so far:\nBegin! This
      is VERY important to you, your job depends on it!\n\nCurrent Task: Just say
      hi.\n"}], "model": "gpt-4", "n": 1, "stop": ["\nObservation"], "stream": true,
      "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1844'
      content-type:
      - application/json
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8rhspCvEbsvPS4sqhq4y1YdATARe8","object":"chat.completion.chunk","created":1707810763,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhspCvEbsvPS4sqhq4y1YdATARe8","object":"chat.completion.chunk","created":1707810763,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Thought"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhspCvEbsvPS4sqhq4y1YdATARe8","object":"chat.completion.chunk","created":1707810763,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhspCvEbsvPS4sqhq4y1YdATARe8","object":"chat.completion.chunk","created":1707810763,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhspCvEbsvPS4sqhq4y1YdATARe8","object":"chat.completion.chunk","created":1707810763,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhspCvEbsvPS4sqhq4y1YdATARe8","object":"chat.completion.chunk","created":1707810763,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhspCvEbsvPS4sqhq4y1YdATARe8","object":"chat.completion.chunk","created":1707810763,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhspCvEbsvPS4sqhq4y1YdATARe8","object":"chat.completion.chunk","created":1707810763,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhspCvEbsvPS4sqhq4y1YdATARe8","object":"chat.completion.chunk","created":1707810763,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhspCvEbsvPS4sqhq4y1YdATARe8","object":"chat.completion.chunk","created":1707810763,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhspCvEbsvPS4sqhq4y1YdATARe8","object":"chat.completion.chunk","created":1707810763,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhspCvEbsvPS4sqhq4y1YdATARe8","object":"chat.completion.chunk","created":1707810763,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        No"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhspCvEbsvPS4sqhq4y1YdATARe8","object":"chat.completion.chunk","created":1707810763,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhspCvEbsvPS4sqhq4y1YdATARe8","object":"chat.completion.chunk","created":1707810763,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhspCvEbsvPS4sqhq4y1YdATARe8","object":"chat.completion.chunk","created":1707810763,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhspCvEbsvPS4sqhq4y1YdATARe8","object":"chat.completion.chunk","created":1707810763,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhspCvEbsvPS4sqhq4y1YdATARe8","object":"chat.completion.chunk","created":1707810763,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Hi"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhspCvEbsvPS4sqhq4y1YdATARe8","object":"chat.completion.chunk","created":1707810763,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854b7e58a86396bd-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 07:52:44 GMT
      Server:
      - cloudflare
      Set-Cookie:
      - __cf_bm=ekbunvLjlKw1wBObm.Z06gP3RwvLklbAs9BafHKp6XU-1707810764-1-AdDxHIcgcfyysbH9HClmca3zKZ21/1nfO/gh2HmZ7K/tWMj4s2fyfo/soGaeloPmutmxxcsYg54G0sUdetdxW9g=;
        path=/; expires=Tue, 13-Feb-24 08:22:44 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=ExVLSHo9ce1_VI6FUGajBgdeioBu.pQJBasoE5elHTw-1707810764936-0-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '475'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299564'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 87ms
      x-request-id:
      - req_84c98ea39768983a85efdb4fdf09276e
    status:
      code: 200
      message: OK
- request:
    body: !!binary |
      CuMLCiQKIgoMc2VydmljZS5uYW1lEhIKEGNyZXdBSS10ZWxlbWV0cnkSugsKEgoQY3Jld2FpLnRl
      bGVtZXRyeRKjCwoQ3h18Sj2MDKiA1ARutuRWOBIIU3KrE137V6EqDENyZXcgQ3JlYXRlZDABOeiy
      sDfXXLMXQQAgszfXXLMXShoKDmNyZXdhaV92ZXJzaW9uEggKBjAuMTAuMkoaCg5weXRob25fdmVy
      c2lvbhIICgYzLjExLjdKMQoHY3Jld19pZBImCiQ4ZDRiNTNlOC0yNWY2LTQ1NjUtOTI1Ni02YWQw
      MDI2ODgzMDhKHAoMY3Jld19wcm9jZXNzEgwKCnNlcXVlbnRpYWxKFQoNY3Jld19sYW5ndWFnZRIE
      CgJlbkoaChRjcmV3X251bWJlcl9vZl90YXNrcxICGAJKGwoVY3Jld19udW1iZXJfb2ZfYWdlbnRz
      EgIYAkr9BAoLY3Jld19hZ2VudHMS7QQK6gRbeyJpZCI6ICIxODhhZDQ1My0yZTJmLTRlN2YtOThh
      Mi0wYWEwMDdiYmEyOTgiLCAicm9sZSI6ICJ0ZXN0IHJvbGUiLCAibWVtb3J5X2VuYWJsZWQ/Ijog
      dHJ1ZSwgInZlcmJvc2U/IjogdHJ1ZSwgIm1heF9pdGVyIjogMTUsICJtYXhfcnBtIjogMTAsICJp
      MThuIjogImVuIiwgImxsbSI6ICJ7XCJuYW1lXCI6IG51bGwsIFwibW9kZWxfbmFtZVwiOiBcImdw
      dC00XCIsIFwidGVtcGVyYXR1cmVcIjogMC43LCBcImNsYXNzXCI6IFwiQ2hhdE9wZW5BSVwifSIs
      ICJkZWxlZ2F0aW9uX2VuYWJsZWQ/IjogdHJ1ZSwgInRvb2xzX25hbWVzIjogW119LCB7ImlkIjog
      IjZhM2FiMTczLTE4MGMtNDBjNi1hZDA1LWQ4ZmM2NmZlZDAxNyIsICJyb2xlIjogInRlc3Qgcm9s
      ZTIiLCAibWVtb3J5X2VuYWJsZWQ/IjogdHJ1ZSwgInZlcmJvc2U/IjogdHJ1ZSwgIm1heF9pdGVy
      IjogMiwgIm1heF9ycG0iOiBudWxsLCAiaTE4biI6ICJlbiIsICJsbG0iOiAie1wibmFtZVwiOiBu
      dWxsLCBcIm1vZGVsX25hbWVcIjogXCJncHQtNFwiLCBcInRlbXBlcmF0dXJlXCI6IDAuNywgXCJj
      bGFzc1wiOiBcIkNoYXRPcGVuQUlcIn0iLCAiZGVsZWdhdGlvbl9lbmFibGVkPyI6IHRydWUsICJ0
      b29sc19uYW1lcyI6IFtdfV1KlwIKCmNyZXdfdGFza3MSiAIKhQJbeyJpZCI6ICJjZDA1ZjAyMy01
      MWI4LTQ5OGEtYTAwNC1lN2E5NzE0NjAwMDEiLCAiYXN5bmNfZXhlY3V0aW9uPyI6IGZhbHNlLCAi
      YWdlbnRfcm9sZSI6ICJ0ZXN0IHJvbGUiLCAidG9vbHNfbmFtZXMiOiBbXX0sIHsiaWQiOiAiNWJi
      YzZlZmYtMzQ5OS00MzM3LTkxYTEtNWVjMzZlOWU4NDk3IiwgImFzeW5jX2V4ZWN1dGlvbj8iOiBm
      YWxzZSwgImFnZW50X3JvbGUiOiAidGVzdCByb2xlMiIsICJ0b29sc19uYW1lcyI6IFsiZ2V0X2Zp
      bmFsX2Fuc3dlciJdfV1KKAoIcGxhdGZvcm0SHAoabWFjT1MtMTQuMy1hcm02NC1hcm0tNjRiaXRK
      HAoQcGxhdGZvcm1fcmVsZWFzZRIICgYyMy4zLjBKGwoPcGxhdGZvcm1fc3lzdGVtEggKBkRhcndp
      bkp7ChBwbGF0Zm9ybV92ZXJzaW9uEmcKZURhcndpbiBLZXJuZWwgVmVyc2lvbiAyMy4zLjA6IFdl
      ZCBEZWMgMjAgMjE6MzA6NTkgUFNUIDIwMjM7IHJvb3Q6eG51LTEwMDAyLjgxLjV+Ny9SRUxFQVNF
      X0FSTTY0X1Q2MDMwSgoKBGNwdXMSAhgMegIYAQ==
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '1510'
      Content-Type:
      - application/x-protobuf
      User-Agent:
      - OTel-OTLP-Exporter-Python/1.22.0
    method: POST
    uri: http://telemetry.crewai.com:4318/v1/traces
  response:
    body:
      string: "\n\0"
    headers:
      Content-Length:
      - '2'
      Content-Type:
      - application/x-protobuf
      Date:
      - Tue, 13 Feb 2024 07:52:46 GMT
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Progressively summarize the
      lines of conversation provided, adding onto the previous summary returning a
      new summary.\n\nEXAMPLE\nCurrent summary:\nThe human asks what the AI thinks
      of artificial intelligence. The AI thinks artificial intelligence is a force
      for good.\n\nNew lines of conversation:\nHuman: Why do you think artificial
      intelligence is a force for good?\nAI: Because artificial intelligence will
      help humans reach their full potential.\n\nNew summary:\nThe human asks what
      the AI thinks of artificial intelligence. The AI thinks artificial intelligence
      is a force for good because it will help humans reach their full potential.\nEND
      OF EXAMPLE\n\nCurrent summary:\n\n\nNew lines of conversation:\nHuman: Just
      say hi.\nAI: Hi\n\nNew summary:"}], "model": "gpt-4", "n": 1, "stream": false,
      "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '866'
      content-type:
      - application/json
      cookie:
      - __cf_bm=ekbunvLjlKw1wBObm.Z06gP3RwvLklbAs9BafHKp6XU-1707810764-1-AdDxHIcgcfyysbH9HClmca3zKZ21/1nfO/gh2HmZ7K/tWMj4s2fyfo/soGaeloPmutmxxcsYg54G0sUdetdxW9g=;
        _cfuvid=ExVLSHo9ce1_VI6FUGajBgdeioBu.pQJBasoE5elHTw-1707810764936-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1SQQU8CMRCF7/srJj0vhFUChJt6MEaNFzQmxpDSHbeVbqd2BpUY/rvpsoBeenhv
        3vSb91MAKFerOShjtZg2+sEsWebHxdXsq7l70Pi5fjZP39Xz5e399c2HKnOCVu9o5JAaGmqjR3EU
        9rZJqAXz1mo6ms6q0XQy6YyWavQ51kQZjAejSXXeJyw5g6zm8FIAAPx0b2YLNX6rOYzKg9Iis25Q
        zY9DACqRz4rSzI5FB1HlyTQUBEOHu7AIdtPqAC6wpI0RBrEIFzcgBOza6LfAegvWlVn5ss7Yw0RC
        jhRqBm0MpdqFxm+Hqv9ndwT01MREq3xM2Hh/1N9ccGyXCTVTyDAsFPfxXQHw2hWx+XebionaKEuh
        NYa8sBqP9/vUqfM/7qw3hUT7P/rkrOgJFW9ZsF2+udBgisl1vWTOYlf8AgAA//8DADZsF+MOAgAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854b7e673a5796bd-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 13 Feb 2024 07:52:47 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '1019'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299799'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 40ms
      x-request-id:
      - req_d48ce211d0a04cfc5f78e9a5cddfe8cc
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role2.\ntest backstory2\n\nYour
      personal goal is: test goal2TOOLS:\n------\nYou have access to only the following
      tools:\n\n(\"get_final_answer: get_final_answer(numbers) -> float - Get the
      final answer but don''t give it yet, just re-use this\\n        tool non-stop.\\nDelegate
      work to co-worker: Delegate work to co-worker(coworker: str, task: str, context:
      str) - Delegate a specific task to one of the following co-workers:\\n- test
      role.\\nThe input to this tool should be the role of the coworker, the task
      you want them to do, and ALL necessary context to exectue the task, they know
      nothing about the task, so share absolute everything you know, don''t reference
      things but instead explain them.\\nAsk question to co-worker: Ask question to
      co-worker(coworker: str, question: str, context: str) - Ask a specific question
      to one of the following co-workers:\\n- test role.\\nThe input to this tool
      should be the role of the coworker, the question you have for them, and ALL
      necessary context to ask the question properly, they know nothing about the
      question, so share absolute everything you know, don''t reference things but
      instead explain them.\",)\n\nTo use a tool, please use the exact following format:\n\n```\nThought:
      Do I need to use a tool? Yes\nAction: the tool you wanna use, should be one
      of [get_final_answer, Delegate work to co-worker, Ask question to co-worker],
      just the name.\nAction Input: Any and all relevant information input and context
      for using the tool\nObservation: the result of using the tool\n```\n\nWhen you
      have a response for your task, or if you do not need to use a tool, you MUST
      use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer:
      [your response here]```This is the summary of your work so far:\nBegin! This
      is VERY important to you, your job depends on it!\n\nCurrent Task: Don''t give
      a Final Answer, instead keep using the `get_final_answer` tool non-stop\nThis
      is the context you''re working with:\nHi\n"}], "model": "gpt-4", "n": 1, "stop":
      ["\nObservation"], "stream": true, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2122'
      content-type:
      - application/json
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Thought"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Yes"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        get"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Input"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        {\""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"numbers"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        ["},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"1"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"2"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"3"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"4"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"5"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"]}"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhstF7PhhhAQ2xsL5Bfwi7iW7e2v","object":"chat.completion.chunk","created":1707810767,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854b7e708f6367f0-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 07:52:48 GMT
      Server:
      - cloudflare
      Set-Cookie:
      - __cf_bm=_3Xz29EpTWd1fXrHSCAMVQiapRM7bR7r4Se5RTQ.8xo-1707810768-1-Af6JfE9ZG9r2FkMTT1T56N8+kKSwlnanZ8s+QGDQ+yteu4/rQroGuV6fXcLUEZ1kl1ghIa0FumObZh5CqQs0fqI=;
        path=/; expires=Tue, 13-Feb-24 08:22:48 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=T8lZXFLAXeAYfjKfyYNfZBPS_oTTJyhTV.wSPhG4myA-1707810768062-0-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '331'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299495'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 101ms
      x-request-id:
      - req_15ced54622f20ca04d3e769b4c2aecd9
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role2.\ntest backstory2\n\nYour
      personal goal is: test goal2TOOLS:\n------\nYou have access to only the following
      tools:\n\n(\"get_final_answer: get_final_answer(numbers) -> float - Get the
      final answer but don''t give it yet, just re-use this\\n        tool non-stop.\\nDelegate
      work to co-worker: Delegate work to co-worker(coworker: str, task: str, context:
      str) - Delegate a specific task to one of the following co-workers:\\n- test
      role.\\nThe input to this tool should be the role of the coworker, the task
      you want them to do, and ALL necessary context to exectue the task, they know
      nothing about the task, so share absolute everything you know, don''t reference
      things but instead explain them.\\nAsk question to co-worker: Ask question to
      co-worker(coworker: str, question: str, context: str) - Ask a specific question
      to one of the following co-workers:\\n- test role.\\nThe input to this tool
      should be the role of the coworker, the question you have for them, and ALL
      necessary context to ask the question properly, they know nothing about the
      question, so share absolute everything you know, don''t reference things but
      instead explain them.\",)\n\nTo use a tool, please use the exact following format:\n\n```\nThought:
      Do I need to use a tool? Yes\nAction: the tool you wanna use, should be one
      of [get_final_answer, Delegate work to co-worker, Ask question to co-worker],
      just the name.\nAction Input: Any and all relevant information input and context
      for using the tool\nObservation: the result of using the tool\n```\n\nWhen you
      have a response for your task, or if you do not need to use a tool, you MUST
      use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer:
      [your response here]```This is the summary of your work so far:\nBegin! This
      is VERY important to you, your job depends on it!\n\nCurrent Task: Don''t give
      a Final Answer, instead keep using the `get_final_answer` tool non-stop\nThis
      is the context you''re working with:\nHi\nThought: Do I need to use a tool?
      Yes\nAction: get_final_answer\nAction Input: {\"numbers\": [1, 2, 3, 4, 5]}\nObservation:
      Actually, I used too many tools, so I''ll stop now and give you my absolute
      BEST Final answer NOW, using exaclty the expected format bellow: \n```\nThought:
      Do I need to use a tool? No\nFinal Answer: [your response here]```\nThought:
      "}], "model": "gpt-4", "n": 1, "stop": ["\nObservation"], "stream": true, "temperature":
      0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2479'
      content-type:
      - application/json
      cookie:
      - __cf_bm=_3Xz29EpTWd1fXrHSCAMVQiapRM7bR7r4Se5RTQ.8xo-1707810768-1-Af6JfE9ZG9r2FkMTT1T56N8+kKSwlnanZ8s+QGDQ+yteu4/rQroGuV6fXcLUEZ1kl1ghIa0FumObZh5CqQs0fqI=;
        _cfuvid=T8lZXFLAXeAYfjKfyYNfZBPS_oTTJyhTV.wSPhG4myA-1707810768062-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Yes"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        get"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Input"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        {\""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"numbers"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        ["},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"6"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"7"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"8"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"9"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"10"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"]}"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rhsxWyximYThzmLvxQht2X0h4zvj","object":"chat.completion.chunk","created":1707810771,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854b7e894dfd67f0-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 07:52:51 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '322'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299408'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 118ms
      x-request-id:
      - req_31b52fa3f1eea8ebdfc28d6c86c63881
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "\n                                The
      schema should have the following structure, only two key:\n                                -
      tool_name: str\n                                - arguments: dict (with all
      arguments being passed)\n\n                                Example:\n                                {\"tool_name\":
      \"tool_name\", \"arguments\": {\"arg_name1\": \"value\", \"arg_name2\": 2}}\n                            "},
      {"role": "user", "content": "Tools available:\n\nTool Name: get_final_answer\nTool
      Description: get_final_answer(numbers) -> float - Get the final answer but don''t
      give it yet, just re-use this\n        tool non-stop.\nTool Arguments: {''numbers'':
      {}}\n--\nTool Name: delegate work to co-worker\nTool Description: Delegate work
      to co-worker(coworker: str, task: str, context: str) - Delegate a specific task
      to one of the following co-workers:\n- test role.\nThe input to this tool should
      be the role of the coworker, the task you want them to do, and ALL necessary
      context to exectue the task, they know nothing about the task, so share absolute
      everything you know, don''t reference things but instead explain them.\nTool
      Arguments: {''coworker'': {''type'': ''string''}, ''task'': {''type'': ''string''},
      ''context'': {''type'': ''string''}}\n--\nTool Name: ask question to co-worker\nTool
      Description: Ask question to co-worker(coworker: str, question: str, context:
      str) - Ask a specific question to one of the following co-workers:\n- test role.\nThe
      input to this tool should be the role of the coworker, the question you have
      for them, and ALL necessary context to ask the question properly, they know
      nothing about the question, so share absolute everything you know, don''t reference
      things but instead explain them.\nTool Arguments: {''coworker'': {''type'':
      ''string''}, ''question'': {''type'': ''string''}, ''context'': {''type'': ''string''}}\n\nReturn
      a valid schema for the tool, use this text to inform a valid ouput schema:\nDo
      I need to use a tool? Yes\nTool Name: get_final_answer\nTool Arguments: {\"numbers\":
      [6, 7, 8, 9, 10]}```"}], "model": "gpt-4", "function_call": {"name": "InstructorToolCalling"},
      "functions": [{"name": "InstructorToolCalling", "description": "Correctly extracted
      `InstructorToolCalling` with all the required parameters with correct types",
      "parameters": {"properties": {"tool_name": {"description": "The name of the
      tool to be called.", "title": "Tool Name", "type": "string"}, "arguments": {"description":
      "A dictinary of arguments to be passed to the tool.", "title": "Arguments",
      "type": "object"}}, "required": ["arguments", "tool_name"], "type": "object"}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2652'
      content-type:
      - application/json
      cookie:
      - __cf_bm=_3Xz29EpTWd1fXrHSCAMVQiapRM7bR7r4Se5RTQ.8xo-1707810768-1-Af6JfE9ZG9r2FkMTT1T56N8+kKSwlnanZ8s+QGDQ+yteu4/rQroGuV6fXcLUEZ1kl1ghIa0FumObZh5CqQs0fqI=;
        _cfuvid=T8lZXFLAXeAYfjKfyYNfZBPS_oTTJyhTV.wSPhG4myA-1707810768062-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1yRT4vbMBDF7/4Uw5ydYnebOPG1sHRL6aUtFNaLUZSJrVbSuNKY/gn+7kVO1snu
        xZh57/14mjllAGgOWAPqXol2g11tQy/l/b/xo/ulP33efdP3tPvw/XB82PXmC+YpwfsfpOU59Uaz
        GyyJYX+WdSAllKhlVVTbsqiq9Sw4PpBNsW6Q1btVsSnvLomejaaINTxmAACn+Zu6+QP9wRqK/Hni
        KEbVEdaLCQAD2zRBFaOJorxgfhU1eyGf6vrR2hvhOHqdWrdaWfsCCIBeuRn54KOEUQuHr8z2vbLW
        +O4GD4AqdKMjL6k/nhoP0KAw2zYxGqyhwY6kPRqvbKt8/E2hwfzsW7LJN2fT1I9uT2GePW5yqHLY
        5rDLoSyekmVq/IRLg+nyNy07stwNgffx1ZPxaLyJfRtIRfapbBQezqAEeZpvMb5YLw6B3SCt8E/y
        Cbh+W515eD37Vb3bXkRhUfYmtVlnl4YY/0Yhl9bRURiCWU6TTdl/AAAA//8DAHe7OWmRAgAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854b7ea16bae67f0-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 13 Feb 2024 07:52:58 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '2921'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299489'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 102ms
      x-request-id:
      - req_50ac5080b8e3e87bc258b0e95a0f6cf0
    status:
      code: 200
      message: OK
- request:
    body: !!binary |
      CowCCiQKIgoMc2VydmljZS5uYW1lEhIKEGNyZXdBSS10ZWxlbWV0cnkS4wEKEgoQY3Jld2FpLnRl
      bGVtZXRyeRLMAQoQQxE88J/bOakKhg2snKDXyRIITKf5fmwoN24qClRvb2wgVXNhZ2UwATlgRg3R
      2lyzF0H49w7R2lyzF0ofCgl0b29sX25hbWUSEgoQZ2V0X2ZpbmFsX2Fuc3dlckoOCghhdHRlbXB0
      cxICGAFKWQoDbGxtElIKUHsibmFtZSI6IG51bGwsICJtb2RlbF9uYW1lIjogImdwdC00IiwgInRl
      bXBlcmF0dXJlIjogMC43LCAiY2xhc3MiOiAiQ2hhdE9wZW5BSSJ9egIYAQ==
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '271'
      Content-Type:
      - application/x-protobuf
      User-Agent:
      - OTel-OTLP-Exporter-Python/1.22.0
    method: POST
    uri: http://telemetry.crewai.com:4318/v1/traces
  response:
    body:
      string: "\n\0"
    headers:
      Content-Length:
      - '2'
      Content-Type:
      - application/x-protobuf
      Date:
      - Tue, 13 Feb 2024 07:53:01 GMT
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Progressively summarize the
      lines of conversation provided, adding onto the previous summary returning a
      new summary.\n\nEXAMPLE\nCurrent summary:\nThe human asks what the AI thinks
      of artificial intelligence. The AI thinks artificial intelligence is a force
      for good.\n\nNew lines of conversation:\nHuman: Why do you think artificial
      intelligence is a force for good?\nAI: Because artificial intelligence will
      help humans reach their full potential.\n\nNew summary:\nThe human asks what
      the AI thinks of artificial intelligence. The AI thinks artificial intelligence
      is a force for good because it will help humans reach their full potential.\nEND
      OF EXAMPLE\n\nCurrent summary:\n\n\nNew lines of conversation:\nHuman: Don''t
      give a Final Answer, instead keep using the `get_final_answer` tool non-stop\nThis
      is the context you''re working with:\nHi\nAI: Agent stopped due to iteration
      limit or time limit.\n\nNew summary:"}], "model": "gpt-4", "n": 1, "stream":
      false, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1031'
      content-type:
      - application/json
      cookie:
      - __cf_bm=_3Xz29EpTWd1fXrHSCAMVQiapRM7bR7r4Se5RTQ.8xo-1707810768-1-Af6JfE9ZG9r2FkMTT1T56N8+kKSwlnanZ8s+QGDQ+yteu4/rQroGuV6fXcLUEZ1kl1ghIa0FumObZh5CqQs0fqI=;
        _cfuvid=T8lZXFLAXeAYfjKfyYNfZBPS_oTTJyhTV.wSPhG4myA-1707810768062-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1RRTU/jMBC951eMfOHSVg2UptvbClaCA+xlpUVCqHKTITFrz1ieCVCh/veVk36I
        iyW/N+/5zfNXAWBcY9Zg6s5qHaKfrlKni6ffO798eFyEso3Xn7tleVv9vaZfN2aSFbx9w1qPqlnN
        IXpUxzTSdUKrmF3Lal6tynlVrQYicIM+y9qo08V0viyvDoqOXY1i1vBcAAB8DWfORg1+mjXMJ0ck
        oIht0axPQwAmsc+IsSJO1JKayZmsmRRpiPunQ+j6YAkciaa+VgHtEH7egzIQK7TuHcHCqyPrwZJ8
        YAJLTaazj6Oee/E76AUH5UWLuhmmN+P0BSizn8Edf+A7psnR37ZICqIcBZoes6FTTDbXBt4Fp8AJ
        1AUcbzNz2GB/Wt1zGxNvc03Ue3/CXx056TYJrTDlNfMro3xfALwMFfffWjMxcYi6Uf6HJMNP/Rj9
        zPk3z+zV6kAqq/Vn/LKsikNCIztRDLmLFlNMbmg85yz2xX8AAAD//wMA1d2iEmgCAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854b7eb67e0d67f0-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 13 Feb 2024 07:53:03 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '4321'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299758'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 48ms
      x-request-id:
      - req_9755a87a23605b945dcae8d17bbb2eb4
    status:
      code: 200
      message: OK
version: 1
