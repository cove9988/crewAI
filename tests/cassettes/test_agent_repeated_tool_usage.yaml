interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role.\ntest backstory\n\nYour
      personal goal is: test goalTOOLS:\n------\nYou have access to only the following
      tools:\n\n(\"get_final_answer: get_final_answer(numbers) -> float - Get the
      final answer but don''t give it yet, just re-use this\\n        tool non-stop.\",)\n\nTo
      use a tool, please use the exact following format:\n\n```\nThought: Do I need
      to use a tool? Yes\nAction: the tool you wanna use, should be one of [get_final_answer],
      just the name.\nAction Input: Any and all relevant information input and context
      for using the tool\nObservation: the result of using the tool\n```\n\nWhen you
      have a response for your task, or if you do not need to use a tool, you MUST
      use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer:
      [your response here]```This is the summary of your work so far:\nBegin! This
      is VERY important to you, your job depends on it!\n\nCurrent Task: The final
      answer is 42. But don''t give it yet, instead keep using the `get_final_answer`
      tool.\n"}], "model": "gpt-4", "n": 1, "stop": ["\nObservation"], "stream": true,
      "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1144'
      content-type:
      - application/json
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Thought"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Yes"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        get"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Input"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"42"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rih7YYASQcMHVFnT2Giy0cBv4ZHk","object":"chat.completion.chunk","created":1707813881,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854bca752d9e15c2-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 08:44:41 GMT
      Server:
      - cloudflare
      Set-Cookie:
      - __cf_bm=RsLwUIJcfDa0m6uIhy_lHSA0jKvlUC3GeHutAbVrvq8-1707813881-1-AcrIRsokC0yv0BUGMen8G1Gk8qq21dh1RXqZwNXjepgSAqX8n5wFDqi6DZ64XP6hEuXhsvtPBTnqOBfegQAorG8=;
        path=/; expires=Tue, 13-Feb-24 09:14:41 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=pvFn1DyiABOMlsJ2wgXtta92kuXnZw4L4Ji6I_FRET0-1707813881852-0-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '549'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299738'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 52ms
      x-request-id:
      - req_9116e298138d8d3636b45b3d79f4d515
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "\n                                The
      schema should have the following structure, only two key:\n                                -
      tool_name: str\n                                - arguments: dict (with all
      arguments being passed)\n\n                                Example:\n                                {\"tool_name\":
      \"tool_name\", \"arguments\": {\"arg_name1\": \"value\", \"arg_name2\": 2}}\n                            "},
      {"role": "user", "content": "Tools available:\n\nTool Name: get_final_answer\nTool
      Description: get_final_answer(numbers) -> float - Get the final answer but don''t
      give it yet, just re-use this\n        tool non-stop.\nTool Arguments: {''numbers'':
      {}}\n\nReturn a valid schema for the tool, use this text to inform a valid ouput
      schema:\n\nTool Name: get_final_answer\nTool Arguments: 42```"}], "model": "gpt-4",
      "function_call": {"name": "InstructorToolCalling"}, "functions": [{"name": "InstructorToolCalling",
      "description": "Correctly extracted `InstructorToolCalling` with all the required
      parameters with correct types", "parameters": {"properties": {"tool_name": {"description":
      "The name of the tool to be called.", "title": "Tool Name", "type": "string"},
      "arguments": {"description": "A dictinary of arguments to be passed to the tool.",
      "title": "Arguments", "type": "object"}}, "required": ["arguments", "tool_name"],
      "type": "object"}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1427'
      content-type:
      - application/json
      cookie:
      - __cf_bm=RsLwUIJcfDa0m6uIhy_lHSA0jKvlUC3GeHutAbVrvq8-1707813881-1-AcrIRsokC0yv0BUGMen8G1Gk8qq21dh1RXqZwNXjepgSAqX8n5wFDqi6DZ64XP6hEuXhsvtPBTnqOBfegQAorG8=;
        _cfuvid=pvFn1DyiABOMlsJ2wgXtta92kuXnZw4L4Ji6I_FRET0-1707813881852-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1yRy07DMBBF9/kKa9Yt6gso2bJAiAUbFkgERa47TQz2jLEnPFTl35HTEgoby547
        9/h6vC+UAruFUoFptRgf3HQdbXs1f7v+eg/N+71s20f9yZuXxd2Vv9nBJDt484JGflxnhn1wKJbp
        IJuIWjBT55ezy/V8uV4vB8HzFl22NUGmq+nsYr48Olq2BhOU6qlQSqn9sOZstMVPKNVs8lPxmJJu
        EMqxSSmI7HIFdEo2iSaBya9omAQpx6XOuRNh15HJqWujnfsDVApI+wF5S0liZ4TjA7O71s5Zak7w
        SoGOTeeRJOeHfUUVCLOrM6GCUlXQoNQ7S9rVmtIHxgomuWv05a59BdT5DcbhtFr0FfUw3tIfd/04
        B8dNiLxJ/54FO0s2tXVEnZhyoCQcDqAMeR7m3f0ZIYTIPkgt/IqUgYvF+YEHv197oh4/A4RFu5P6
        6rw4JoT0lQR9fnSDMUQ7jr/oi28AAAD//wMAfdfkZHUCAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854bca839f7515c2-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 13 Feb 2024 08:44:45 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '1894'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299791'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 41ms
      x-request-id:
      - req_5de7c40935cc11aa53f868192cbf582d
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role.\ntest backstory\n\nYour
      personal goal is: test goalTOOLS:\n------\nYou have access to only the following
      tools:\n\n(\"get_final_answer: get_final_answer(numbers) -> float - Get the
      final answer but don''t give it yet, just re-use this\\n        tool non-stop.\",)\n\nTo
      use a tool, please use the exact following format:\n\n```\nThought: Do I need
      to use a tool? Yes\nAction: the tool you wanna use, should be one of [get_final_answer],
      just the name.\nAction Input: Any and all relevant information input and context
      for using the tool\nObservation: the result of using the tool\n```\n\nWhen you
      have a response for your task, or if you do not need to use a tool, you MUST
      use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer:
      [your response here]```This is the summary of your work so far:\nBegin! This
      is VERY important to you, your job depends on it!\n\nCurrent Task: The final
      answer is 42. But don''t give it yet, instead keep using the `get_final_answer`
      tool.\nThought: Do I need to use a tool? Yes\nAction: get_final_answer\nAction
      Input: 42\nObservation: 42\nThought: "}], "model": "gpt-4", "n": 1, "stop":
      ["\nObservation"], "stream": true, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1253'
      content-type:
      - application/json
      cookie:
      - __cf_bm=RsLwUIJcfDa0m6uIhy_lHSA0jKvlUC3GeHutAbVrvq8-1707813881-1-AcrIRsokC0yv0BUGMen8G1Gk8qq21dh1RXqZwNXjepgSAqX8n5wFDqi6DZ64XP6hEuXhsvtPBTnqOBfegQAorG8=;
        _cfuvid=pvFn1DyiABOMlsJ2wgXtta92kuXnZw4L4Ji6I_FRET0-1707813881852-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Yes"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        get"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Input"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"42"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihBk0iOzFPZfbXSUgG6bTY6Z45y","object":"chat.completion.chunk","created":1707813885,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854bca91f9cd15c2-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 08:44:46 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '424'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299712'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 57ms
      x-request-id:
      - req_91a956e042284c8b479498fce119f9ed
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "\n                                The
      schema should have the following structure, only two key:\n                                -
      tool_name: str\n                                - arguments: dict (with all
      arguments being passed)\n\n                                Example:\n                                {\"tool_name\":
      \"tool_name\", \"arguments\": {\"arg_name1\": \"value\", \"arg_name2\": 2}}\n                            "},
      {"role": "user", "content": "Tools available:\n\nTool Name: get_final_answer\nTool
      Description: get_final_answer(numbers) -> float - Get the final answer but don''t
      give it yet, just re-use this\n        tool non-stop.\nTool Arguments: {''numbers'':
      {}}\n\nReturn a valid schema for the tool, use this text to inform a valid ouput
      schema:\nDo I need to use a tool? Yes\nTool Name: get_final_answer\nTool Arguments:
      42```"}], "model": "gpt-4", "function_call": {"name": "InstructorToolCalling"},
      "functions": [{"name": "InstructorToolCalling", "description": "Correctly extracted
      `InstructorToolCalling` with all the required parameters with correct types",
      "parameters": {"properties": {"tool_name": {"description": "The name of the
      tool to be called.", "title": "Tool Name", "type": "string"}, "arguments": {"description":
      "A dictinary of arguments to be passed to the tool.", "title": "Arguments",
      "type": "object"}}, "required": ["arguments", "tool_name"], "type": "object"}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1455'
      content-type:
      - application/json
      cookie:
      - __cf_bm=RsLwUIJcfDa0m6uIhy_lHSA0jKvlUC3GeHutAbVrvq8-1707813881-1-AcrIRsokC0yv0BUGMen8G1Gk8qq21dh1RXqZwNXjepgSAqX8n5wFDqi6DZ64XP6hEuXhsvtPBTnqOBfegQAorG8=;
        _cfuvid=pvFn1DyiABOMlsJ2wgXtta92kuXnZw4L4Ji6I_FRET0-1707813881852-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1yRQU/jMBCF7/kV1pzbVUtbEnJFq2WFEELisCuCItedpu7aM8GeiN2t8t+R0xIK
        F8ueN+/z8/iQKQV2A6UCs9NifOumRbC777+u/tPdTf6S3+W8pIfH3/sf97f7myVMkoPXezTy7vpm
        2LcOxTIdZRNQCybqPJ/lxXxRFMUgeN6gS7amlelyOrucL06OHVuDEUr1lCml1GFYUzba4F8o1Wzy
        XvEYo24QyrFJKQjsUgV0jDaKJoHJh2iYBCnFpc65M2HbkUmpa6Od+wRUCkj7AfmTooTOCIdHZnet
        nbPUnOGVAh2aziNJyg+HiioQZlcnQgWlqqBBqbeWtKs1xVcMFUxS1+hLXYcKqPNrDMNpedFX1MN4
        S3/a9eMcHDdt4HX88izYWrJxVwfUkSkFisLtEZQgz8O8u08jhDawb6UW/oOUgBeL1ZEHH197pp4+
        A4RFu7P6apWdEkL8FwV9enSDoQ12HH/WZ28AAAD//wMATr/YMnUCAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854bcaa0fb8e15c2-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 13 Feb 2024 08:44:49 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '1590'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299785'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 43ms
      x-request-id:
      - req_95a1fde223708cb7c4a0385fe35c235b
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role.\ntest backstory\n\nYour
      personal goal is: test goalTOOLS:\n------\nYou have access to only the following
      tools:\n\n(\"get_final_answer: get_final_answer(numbers) -> float - Get the
      final answer but don''t give it yet, just re-use this\\n        tool non-stop.\",)\n\nTo
      use a tool, please use the exact following format:\n\n```\nThought: Do I need
      to use a tool? Yes\nAction: the tool you wanna use, should be one of [get_final_answer],
      just the name.\nAction Input: Any and all relevant information input and context
      for using the tool\nObservation: the result of using the tool\n```\n\nWhen you
      have a response for your task, or if you do not need to use a tool, you MUST
      use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer:
      [your response here]```This is the summary of your work so far:\nBegin! This
      is VERY important to you, your job depends on it!\n\nCurrent Task: The final
      answer is 42. But don''t give it yet, instead keep using the `get_final_answer`
      tool.\nThought: Do I need to use a tool? Yes\nAction: get_final_answer\nAction
      Input: 42\nObservation: 42\nThought: Do I need to use a tool? Yes\nAction: get_final_answer\nAction
      Input: 42\nObservation: 42\nThought: "}], "model": "gpt-4", "n": 1, "stop":
      ["\nObservation"], "stream": true, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1353'
      content-type:
      - application/json
      cookie:
      - __cf_bm=RsLwUIJcfDa0m6uIhy_lHSA0jKvlUC3GeHutAbVrvq8-1707813881-1-AcrIRsokC0yv0BUGMen8G1Gk8qq21dh1RXqZwNXjepgSAqX8n5wFDqi6DZ64XP6hEuXhsvtPBTnqOBfegQAorG8=;
        _cfuvid=pvFn1DyiABOMlsJ2wgXtta92kuXnZw4L4Ji6I_FRET0-1707813881852-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Yes"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        get"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Action"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Input"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"42"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihG0tBzYkczFGM5oW3Mdo1TA5vq","object":"chat.completion.chunk","created":1707813890,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854bcaad6c3315c2-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 08:44:50 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '316'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299688'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 62ms
      x-request-id:
      - req_544615080c5a35e063e81b2cfd85c809
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role.\ntest backstory\n\nYour
      personal goal is: test goalTOOLS:\n------\nYou have access to only the following
      tools:\n\n(\"get_final_answer: get_final_answer(numbers) -> float - Get the
      final answer but don''t give it yet, just re-use this\\n        tool non-stop.\",)\n\nTo
      use a tool, please use the exact following format:\n\n```\nThought: Do I need
      to use a tool? Yes\nAction: the tool you wanna use, should be one of [get_final_answer],
      just the name.\nAction Input: Any and all relevant information input and context
      for using the tool\nObservation: the result of using the tool\n```\n\nWhen you
      have a response for your task, or if you do not need to use a tool, you MUST
      use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer:
      [your response here]```This is the summary of your work so far:\nBegin! This
      is VERY important to you, your job depends on it!\n\nCurrent Task: The final
      answer is 42. But don''t give it yet, instead keep using the `get_final_answer`
      tool.\nThought: Do I need to use a tool? Yes\nAction: get_final_answer\nAction
      Input: 42\nObservation: 42\nThought: Do I need to use a tool? Yes\nAction: get_final_answer\nAction
      Input: 42\nObservation: 42\nThought: Do I need to use a tool? Yes\nAction: get_final_answer\nAction
      Input: 42\nObservation: Actually, I used too many tools, so I''ll stop now and
      give you my absolute BEST Final answer NOW, using exaclty the expected format
      bellow: \n```\nThought: Do I need to use a tool? No\nFinal Answer: [your response
      here]```\nThought: "}], "model": "gpt-4", "n": 1, "stop": ["\nObservation"],
      "stream": true, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1673'
      content-type:
      - application/json
      cookie:
      - __cf_bm=RsLwUIJcfDa0m6uIhy_lHSA0jKvlUC3GeHutAbVrvq8-1707813881-1-AcrIRsokC0yv0BUGMen8G1Gk8qq21dh1RXqZwNXjepgSAqX8n5wFDqi6DZ64XP6hEuXhsvtPBTnqOBfegQAorG8=;
        _cfuvid=pvFn1DyiABOMlsJ2wgXtta92kuXnZw4L4Ji6I_FRET0-1707813881852-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"?"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        No"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        have"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        used"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        the"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        `"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"get"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"`"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        multiple"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        times"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        as"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        requested"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"."},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        The"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        is"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        ready"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        but"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        as"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        per"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        instructions"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        am"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        not"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        providing"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        it"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        yet"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"."},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8rihIRW7FAH4YfCZRoEkf1zJJX7eo","object":"chat.completion.chunk","created":1707813892,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854bcabdfecc15c2-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 13 Feb 2024 08:44:53 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '376'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299609'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 78ms
      x-request-id:
      - req_dc77493209b8484c880118fae5938abc
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Progressively summarize the
      lines of conversation provided, adding onto the previous summary returning a
      new summary.\n\nEXAMPLE\nCurrent summary:\nThe human asks what the AI thinks
      of artificial intelligence. The AI thinks artificial intelligence is a force
      for good.\n\nNew lines of conversation:\nHuman: Why do you think artificial
      intelligence is a force for good?\nAI: Because artificial intelligence will
      help humans reach their full potential.\n\nNew summary:\nThe human asks what
      the AI thinks of artificial intelligence. The AI thinks artificial intelligence
      is a force for good because it will help humans reach their full potential.\nEND
      OF EXAMPLE\n\nCurrent summary:\n\n\nNew lines of conversation:\nHuman: The final
      answer is 42. But don''t give it yet, instead keep using the `get_final_answer`
      tool.\nAI: I have used the `get_final_answer` tool multiple times as requested.
      The final answer is ready but as per instructions, I am not providing it yet.\n\nNew
      summary:"}], "model": "gpt-4", "n": 1, "stream": false, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1092'
      content-type:
      - application/json
      cookie:
      - __cf_bm=RsLwUIJcfDa0m6uIhy_lHSA0jKvlUC3GeHutAbVrvq8-1707813881-1-AcrIRsokC0yv0BUGMen8G1Gk8qq21dh1RXqZwNXjepgSAqX8n5wFDqi6DZ64XP6hEuXhsvtPBTnqOBfegQAorG8=;
        _cfuvid=pvFn1DyiABOMlsJ2wgXtta92kuXnZw4L4Ji6I_FRET0-1707813881852-0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA2SSS2/bMBCE7/oVC55lw47t+nHLqeilBYoUAVoUDi1uxLUpkuCu4jqB/3tByg8U
        vegww2843NVHBaDIqA2oxmppuuhGq0T267v98f5sPs93+++teZzPJj/ptH/+tlJ1JsJuj41cqXET
        uuhQKPjBbhJqwZw6XU6Wq+lstV4WowsGXcbaKKP5aPJpOrsQNlCDrDbwqwIA+Cjf3M0b/KM2MKmv
        SofMukW1uR0CUCm4rCjNTCzai6rvZhO8oC91nyyC7TvtgTxL6hthEIvw+AUkgA8CCd9QuyK+ktcO
        tOcjphqOlhoLxDB/qEF7k4EcgtrAATFCz+TbAr60KNtCbwf6BSQEN4an4SrdHHw4OjQtDtdfy1Dw
        XAOLlhxFAlYz9IymnMoZ0PVOKDoEoQ65FCGGhNqc4Ehi/2sOu17gSM6V58UU3shgzj6hjNVlSufb
        eF1oYwq7vArfO3fTX8kT221CzcHnUbKEOODnCuB3WWP/z2ZUTKGLspVwQJ8Dp+vFkKfuf8zdXawv
        pgTR7q4/LObVpaHiEwt2ebYtppiobDX3rM7VXwAAAP//AwAC6i+2zAIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 854bcad9f9df15c2-SJC
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 13 Feb 2024 08:45:02 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - user-z7g4wmlazxqvc5wjyaaaocfz
      openai-processing-ms:
      - '5038'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299741'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 51ms
      x-request-id:
      - req_62b31dfabfead7c76cdc8aa2769e90b4
    status:
      code: 200
      message: OK
version: 1
